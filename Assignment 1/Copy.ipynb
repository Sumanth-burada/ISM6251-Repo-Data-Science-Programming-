{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let us load the required data into individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/suman/DspData/data/churn_train_X.csv') \n",
    "y_train = pd.read_csv('C:/Users/suman/DspData/data/churn_train_y.csv') \n",
    "X_test = pd.read_csv('C:/Users/suman/DspData/data/churn_test_X.csv') \n",
    "y_test = pd.read_csv('C:/Users/suman/DspData/data/churn_test_y.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a data frame called performance and put all the needed metrics in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 8 is smaller than n_iter=500. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "The best recall score is 0.5669050216135417\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.         0.56690502 0.         0.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.         0.56917868 0.         0.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['None','l1','l2','elasticnet'],\n",
    "    'solver':['saga','liblinear']\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.5695996444875369\n",
      "... with parameters: {'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "penalty = rand_search.best_params_['penalty']\n",
    "solver = rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {  \n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallLogistic = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.57393</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision   Recall        F1\n",
       "0  Logistic Regression  0.903587   0.799458  0.57393  0.668177"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression\",\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees - Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.7861754130812427\n",
      "... with parameters: {'min_samples_split': 19, 'min_samples_leaf': 15, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 66, 'max_depth': 11, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,100),  \n",
    "    'min_samples_leaf': np.arange(1,75),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 80), \n",
    "    'max_depth': np.arange(1,40), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE - GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.7969862238920535\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 65, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 13, 'min_samples_split': 17}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.573930</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.826004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.903587   0.799458  0.573930  0.668177\n",
       "0        Decision Tree  0.940112   0.812030  0.840467  0.826004"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset (only training data)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_up, y_up = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_7920\\1298015926.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_up, y_up)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_up, y_up)\n",
    "\n",
    "rfpred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.573930</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.826004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.945048</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.896887</td>\n",
       "      <td>0.846648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy  Precision    Recall        F1\n",
       "0       Logistic Regression  0.903587   0.799458  0.573930  0.668177\n",
       "0             Decision Tree  0.940112   0.812030  0.840467  0.826004\n",
       "0  Random Forest Classifier  0.945048   0.801739  0.896887  0.846648"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = (confusion_matrix(y_test, rfpred))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest Classifier\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that we don't predict churning as non-churning customers. That's why the model needs to be evaluated on the \"Recall\"- metric\n",
    "\n",
    "Conclusion :The goal of this project is to provide an analysis which shows the difference between a non-churning and churning customer. Using the existing data managed to train a model with upsampled data which reaches a recall score of 89%.This will provide us insight into which customers are eager to churn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s, X_test_s = scaler.transform(X_train), scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.48060017\n",
      "Validation score: 0.839210\n",
      "Iteration 2, loss = 0.32235005\n",
      "Validation score: 0.895628\n",
      "Iteration 3, loss = 0.26217806\n",
      "Validation score: 0.906911\n",
      "Iteration 4, loss = 0.23271762\n",
      "Validation score: 0.909732\n",
      "Iteration 5, loss = 0.21407224\n",
      "Validation score: 0.916784\n",
      "Iteration 6, loss = 0.19722730\n",
      "Validation score: 0.915374\n",
      "Iteration 7, loss = 0.18604824\n",
      "Validation score: 0.908322\n",
      "Iteration 8, loss = 0.17569567\n",
      "Validation score: 0.913963\n",
      "Iteration 9, loss = 0.16658780\n",
      "Validation score: 0.913963\n",
      "Iteration 10, loss = 0.15869492\n",
      "Validation score: 0.918195\n",
      "Iteration 11, loss = 0.15165963\n",
      "Validation score: 0.911142\n",
      "Iteration 12, loss = 0.14473661\n",
      "Validation score: 0.918195\n",
      "Iteration 13, loss = 0.14001538\n",
      "Validation score: 0.913963\n",
      "Iteration 14, loss = 0.13655168\n",
      "Validation score: 0.919605\n",
      "Iteration 15, loss = 0.13147575\n",
      "Validation score: 0.919605\n",
      "Iteration 16, loss = 0.12730806\n",
      "Validation score: 0.919605\n",
      "Iteration 17, loss = 0.12367332\n",
      "Validation score: 0.919605\n",
      "Iteration 18, loss = 0.12072509\n",
      "Validation score: 0.922426\n",
      "Iteration 19, loss = 0.11721138\n",
      "Validation score: 0.922426\n",
      "Iteration 20, loss = 0.11704004\n",
      "Validation score: 0.923836\n",
      "Iteration 21, loss = 0.11332072\n",
      "Validation score: 0.923836\n",
      "Iteration 22, loss = 0.10951702\n",
      "Validation score: 0.926657\n",
      "Iteration 23, loss = 0.10452152\n",
      "Validation score: 0.923836\n",
      "Iteration 24, loss = 0.10002417\n",
      "Validation score: 0.926657\n",
      "Iteration 25, loss = 0.09730656\n",
      "Validation score: 0.925247\n",
      "Iteration 26, loss = 0.09591102\n",
      "Validation score: 0.929478\n",
      "Iteration 27, loss = 0.09148641\n",
      "Validation score: 0.923836\n",
      "Iteration 28, loss = 0.08956362\n",
      "Validation score: 0.928068\n",
      "Iteration 29, loss = 0.08743705\n",
      "Validation score: 0.929478\n",
      "Iteration 30, loss = 0.08423203\n",
      "Validation score: 0.930889\n",
      "Iteration 31, loss = 0.08113693\n",
      "Validation score: 0.929478\n",
      "Iteration 32, loss = 0.07737038\n",
      "Validation score: 0.929478\n",
      "Iteration 33, loss = 0.07531974\n",
      "Validation score: 0.930889\n",
      "Iteration 34, loss = 0.07320292\n",
      "Validation score: 0.930889\n",
      "Iteration 35, loss = 0.07321801\n",
      "Validation score: 0.930889\n",
      "Iteration 36, loss = 0.06831125\n",
      "Validation score: 0.930889\n",
      "Validation score did not improve more than tol=0.000010 for 5 consecutive epochs. Stopping.\n",
      "CPU times: total: 5.84 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(60,50,40), \n",
    "    activation = 'relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001, # Strength of the L2 regularization term\n",
    "    batch_size='auto',\n",
    "    learning_rate = 'constant',\n",
    "    learning_rate_init = 0.001,\n",
    "    max_iter=200,\n",
    "    tol=0.00001, \n",
    "    early_stopping = True,\n",
    "    n_iter_no_change = 5,\n",
    "    verbose=True\n",
    "    \n",
    ")\n",
    "_ = model1.fit(X_train_s, y_train)\n",
    "\n",
    "# Currently (version 1.2.2), MLPClassifier supports only the Cross-Entropy loss function.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48060016857014554,\n",
       " 0.3223500531666497,\n",
       " 0.26217805916973924,\n",
       " 0.2327176194594692,\n",
       " 0.21407224239898323,\n",
       " 0.1972273003284454,\n",
       " 0.1860482361406369,\n",
       " 0.17569566968572922,\n",
       " 0.16658779540564875,\n",
       " 0.1586949231605642,\n",
       " 0.151659628427455,\n",
       " 0.1447366144158229,\n",
       " 0.1400153798368658,\n",
       " 0.13655168484642002,\n",
       " 0.1314757510797693,\n",
       " 0.12730805997759273,\n",
       " 0.1236733166059745,\n",
       " 0.12072509396499922,\n",
       " 0.11721138250124942,\n",
       " 0.11704004340544966,\n",
       " 0.11332071898770292,\n",
       " 0.10951701609491211,\n",
       " 0.10452151968631554,\n",
       " 0.10002417364348773,\n",
       " 0.09730656193186404,\n",
       " 0.09591101940647796,\n",
       " 0.0914864119538316,\n",
       " 0.08956362456300648,\n",
       " 0.08743704922169881,\n",
       " 0.0842320329085246,\n",
       " 0.08113693493822996,\n",
       " 0.07737037774573213,\n",
       " 0.07531973764668895,\n",
       " 0.07320292471292175,\n",
       " 0.07321800703076395,\n",
       " 0.06831125181816657]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 8.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test_s)\n",
    "\n",
    "# from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import matplotlib.pylab as plt\n",
    "\n",
    "# y_train_pred, y_test_pred = (my_model.predict(X_train_s).flatten() > 0.5)*1, (my_model.predict(X_test_s).flatten() > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9553    0.9490    0.9521      2547\n",
      "           1     0.7446    0.7703    0.7572       492\n",
      "\n",
      "    accuracy                         0.9200      3039\n",
      "   macro avg     0.8500    0.8596    0.8547      3039\n",
      "weighted avg     0.9212    0.9200    0.9206      3039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.3 s\n",
      "Wall time: 10min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [ (64,), (128,),(128,64), (64,128), (64,128,196), (196,128,64)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .0001, .0005, .001, .005],\n",
    "    'batch_size': [25, 50, 100],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.0005, 0.001, 0.005, 0.01],\n",
    "    'max_iter': [5000],\n",
    "    'tol': [0.000005, 0.00001, 0.00005],\n",
    "    'early_stopping':[True],\n",
    "    'n_iter_no_change':[5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = MLPClassifier(), # a blank slate... RandomizedSearchCV will send parameters.\n",
    "    param_distributions=param_distributions, \n",
    "    cv=3, \n",
    "    n_iter=300,\n",
    "    scoring='accuracy', # note that we could also choose any other scoring metric that is appropriate for a multi-class problem - such as f1_macro, f1_micro, f1_weighted, etc.\n",
    "    verbose=1, \n",
    "    n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "_ = random_search.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 5e-06, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 5000, 'learning_rate_init': 0.005, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (128, 64), 'early_stopping': True, 'batch_size': 25, 'alpha': 0.0005, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "model2 = random_search.best_estimator_\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9428    0.9768    0.9595      2547\n",
      "           1     0.8525    0.6931    0.7646       492\n",
      "\n",
      "    accuracy                         0.9309      3039\n",
      "   macro avg     0.8976    0.8350    0.8620      3039\n",
      "weighted avg     0.9282    0.9309    0.9279      3039\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 43.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test_s)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 64,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 64,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['sparse_categorical_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 72296689438457593856.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9020\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9006\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9196\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9008\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8933\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9176\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8971\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8993\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9035\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 3068782903912764014592.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2369\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1773\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1202\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0654\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0125\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.9626\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9136\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.8648\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8168\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 11743224974461208887296.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2138\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.1564\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.1027\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.0499\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.9983\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.9470\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.8965\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.8465\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.7967\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 9470820.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2803012.7500\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1372362.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 517162.8438\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 208754.7656\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 132789.4219\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 109881.6641\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 79147.2266\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 77400.6016\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 60909.5117\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 13459490.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3900495.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2093179.1250\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1043360.1250\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 455219.3125\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 204345.1406\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 153518.7500\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 102765.8516\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 72333.4297\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 85805.6953\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 14961603.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5331609.5000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2759741.7500\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1588541.2500\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 867340.8125\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 378749.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 170365.9688\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 107952.7891\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 86446.1484\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 83457.0391\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 65006176.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 17171196.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 10649489.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 9096161.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8862653.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8645613.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7737775.5000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7668290.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8058181.5000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7526810.5000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 57552832.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 31054952.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 20282186.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 13128504.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 10591947.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9946679.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9661156.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9882062.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9293932.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8826496.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 213989888.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 114736336.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 38368312.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 14745527.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 12545904.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 11987161.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 11291191.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 11057896.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 11013753.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 10999335.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 321013632.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 241198256.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 170264848.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 106909320.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 49287720.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 16784580.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 11963717.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7426842.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2893378.7500\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 99676.1016\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 100309200.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 35336800.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 546810.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 20213.5430\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 57606.5352\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 37647.7344\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 54204.6719\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 56706.2695\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 77710.5625\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 68595.1016\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 105511184.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 19518184.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4576489.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 103303.8125\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 87709.0547\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 82719.2188\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 76619.5781\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 79974.8906\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 58011.6602\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 54082.9531\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 9425960352807387136.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6673\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3584\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1409\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9936\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8942\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8257\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7766\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7401\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7119\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1629759494047137792.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6686\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3593\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1416\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.9941\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8946\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8260\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7769\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7404\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7121\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 10353694179464314880.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6677\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3586\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1412\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9937\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8942\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8256\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7766\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7400\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7118\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3286408919341072384.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0092\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7807\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6908\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6417\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6086\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5839\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5646\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5493\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5369\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 172625095087357952.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0104\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7814\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6910\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6417\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6086\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5838\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5645\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5491\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5367\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7235182334952079360.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.0100\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7812\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6909\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6415\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6084\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5838\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5645\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5491\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5367\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 2s 4ms/step - loss: 13267295.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 7133556.5000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 6080849.5000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 4893332.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 3795500.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3183337.5000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2520651.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2312487.7500\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1923718.7500\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1650807.3750\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 2s 4ms/step - loss: 20348902.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 8473646.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 7196608.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 6018874.5000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 4807158.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 4097224.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3207690.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2787203.5000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2502667.7500\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2016072.5000\n",
      "119/119 [==============================] - 1s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 2s 4ms/step - loss: 19171446.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 8000781.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 6561933.5000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 5338315.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4338039.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3603517.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2911345.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 2610724.5000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2116527.5000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1909395.5000\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 318435150004224.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2804\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2655\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2508\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2361\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2216\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2071\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1926\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1783\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1640\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 534406741622784.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2803\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2655\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2508\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2361\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2215\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2070\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1926\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1782\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1639\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 2s 4ms/step - loss: 658876034711552.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2804\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2655\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2508\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2362\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2216\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2071\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1926\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1783\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1640\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 316144261961613312.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2586\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2290\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1995\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1704\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1416\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1133\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0852\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0574\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0300\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 594712645324505088.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2587\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2289\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1995\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1704\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1416\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1132\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.0850\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0573\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0299\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 32387794328354816.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2589\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2291\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1998\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1707\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1419\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1135\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0855\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0577\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0302\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8568867.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1918798.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 192475.2969\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 39546.2695\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 39041.0039\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 52676.0039\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 55561.9062\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 107104.7656\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 85111.0859\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 53303.2969\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 128338488.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 71963328.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 21997230.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 424516.0938\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 47974.5586\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 52495.1641\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 57362.7812\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 41930.9453\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 22553.6094\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 61331.0430\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 43678268.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 27646434.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 21865898.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 16283682.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 10682417.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4931524.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 357025.7812\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 45812.9297\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 76098.4766\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 111179.9141\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6696818.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2489536.7500\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1588587.2500\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 976063.6875\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 743892.7500\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 482336.9375\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 276121.2812\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 84095.7656\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 51889.5820\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 18070.8789\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6616189.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2312170.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1576139.1250\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1123269.8750\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 571334.9375\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 403480.6562\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 158632.4375\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 332304.4062\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 99763.0703\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9691.0117\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5741929.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2497879.5000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 908809.8750\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 498600.7812\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 424275.7188\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 158493.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 174789.6406\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 43135.3516\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1564.8821\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 182.5591\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 85529033839738880.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0883\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9541\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8288\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7124\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6053\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.5074\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4185\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3383\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2662\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3034724033363968.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0882\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9540\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8286\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7121\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6050\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.5070\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4181\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3379\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.2659\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 78229006775746560.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0880\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9540\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8288\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7124\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6051\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5072\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4184\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3382\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2662\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 3568006.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 841457.4375\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 186673.3125\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 32286.5195\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3187.6438\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 626.4363\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 18.8947\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.1906\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4758\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4640\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 12134416.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2881326.2500\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1116774.1250\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 905886.6875\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 247454.0469\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 36144.9297\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2709.4275\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 530.9336\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 121.2396\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 322.2008\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 10254326.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1232371.2500\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 798057.7500\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 76390.1250\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 19625.5078\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3195.7529\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1428.2997\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 31.5591\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7457\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4684\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 19656354.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4588032.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1774311.6250\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1451761.3750\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 970369.6875\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1699605.7500\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 843228.8750\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 295975.5312\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 425935.5000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 83624.0469\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 24746822.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5353018.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2139856.5000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1689563.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2165803.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 917496.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 277996.7500\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 362671.7188\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 147686.9844\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 93671.5547\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 10045041.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2975578.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1351542.3750\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1808761.6250\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 190195.1562\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 98893.6562\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 72378.8438\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 13144.4277\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 8142.0557\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 497.9940\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 17154461669305352192.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.4742\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.5459\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.3001\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2932\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2863\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2795\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2727\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2659\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2593\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 21912398127389736960.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2736\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2676\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2617\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2557\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2498\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2439\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2379\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2320\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2261\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 15551776137263710208.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2733\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2667\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2602\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2536\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2471\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2406\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2341\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2276\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2211\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 13578787183615016960.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0101\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7814\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6914\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6422\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6090\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5842\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5649\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5495\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5371\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 243303953083662336.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0110\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7811\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6906\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6413\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6082\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5836\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5643\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5489\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5366\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 96468203873501184.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0117\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7817\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6911\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6416\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6085\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5838\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5645\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5492\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5368\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 158002432251527168.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2298\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1815\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1341\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0876\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0420\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9973\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9536\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9108\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8690\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 97891873862975488.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2297\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1815\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1341\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0875\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0419\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9972\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9535\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9107\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8688\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 223118448606052352.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2298\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1815\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1342\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0877\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0420\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9974\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9536\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9108\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.8690\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 208972272.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 61946568.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 15291234.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 11693549.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10092548.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10042820.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9413601.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8930596.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8448007.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8323347.5000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 185951424.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 32381954.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 14790078.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 13634935.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 12739528.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 12298883.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 12236902.0000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 11270183.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 11165656.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 10860032.0000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 19404028.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 10478855.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 9564583.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 8886665.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 7690755.5000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 7289078.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6524656.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6154999.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5416809.0000\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5313273.0000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 30704638.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4505546.5000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2820709.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1560569.1250\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 625136.1875\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 373438.4688\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 227344.3281\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 163417.9219\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 170951.8750\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 166155.7500\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 12828392.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6534137.5000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3896872.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2232460.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1030184.7500\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 498830.2812\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 276410.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 195293.5312\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 228104.1875\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 208638.8281\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 17696768.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4695048.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2689714.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1447138.3750\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 694157.6875\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 452510.4375\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 339244.0312\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 505584.5625\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 233963.2500\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 168267.7656\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 10226748964967809024.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6673\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3584\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1409\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9936\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8942\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8257\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7766\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7401\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7119\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 11852374707611369472.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6673\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3582\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1405\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9931\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.8937\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8251\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7761\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7396\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.7114\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 24551195247726559232.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6690\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3598\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1422\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9947\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8951\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8264\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7773\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7408\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7125\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 3865966171266220032.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.8227\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.8125\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.8038\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.8006\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.8023\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7937\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 0.7855\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7843\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7911\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 7459181440832372736.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6903\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 0.6831\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6815\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6902\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 0.6849\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6748\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6888\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6910\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 0.6722\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7666544935784415232.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 0.8653\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.8644\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 0.9445\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.9246\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.9331\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.9216\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.9228\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.9270\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.9118\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7698293.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1624127.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1165235.7500\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1858887.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1506752.3750\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1775258.6250\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1400397.3750\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1252889.6250\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1001931.5625\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1000660.2500\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4749767.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1968003.3750\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1120904.1250\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 855864.5000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1548282.2500\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1436226.8750\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1164981.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 803907.1875\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1135415.3750\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 808561.6875\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2945325.7500\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1349784.3750\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1079812.7500\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1225507.5000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 534982.8750\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 916703.6250\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 698694.6875\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 604443.8750\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 600755.3125\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 466908.9375\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 8566941604839948288.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.6673\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3584\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1409\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9936\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8942\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8257\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7766\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7401\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7119\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 7716408337859870720.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6673\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3582\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1405\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9931\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8937\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8251\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7761\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7396\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7114\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 11286747443376422912.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.6677\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3586\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1412\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9937\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8942\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8256\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7766\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7400\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.7118\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 8938396764877094912.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6681\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3589\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1412\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9938\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8944\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8258\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7767\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7402\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7119\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 4667266880967278592.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6675\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3583\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.1407\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.9932\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8938\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8253\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7762\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7397\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7115\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 10973509774762573824.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6677\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3586\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1412\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.9937\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8942\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.8256\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7766\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7400\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.7118\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 76154874151115859347636224.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8153\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.4886\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1950\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9657\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8149\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7250\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6699\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6332\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.6061\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 15710040463166223666905088.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.7770\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4308\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.1389\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.9330\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8106\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7396\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6942\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6609\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6339\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 421497221387563527307264.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8246\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5279\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2622\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.0401\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.8781\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7723\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7057\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.6613\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.6298\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 42252552.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8929626.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 8356023.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 7675293.5000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 7007922.5000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6554645.5000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5563269.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5520688.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5125499.5000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 4292098.5000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 48843516.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 9576310.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8176932.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8065583.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 6995175.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6510256.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6196841.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5550959.5000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5214589.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4820382.0000\n",
      "40/40 [==============================] - 0s 5ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 42586904.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8489100.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 6757011.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 6344084.5000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5694293.5000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5206340.5000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4779656.5000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 4369783.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4048041.5000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3681999.7500\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2712882269650944.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 3090943544655872.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2585849753501696.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3744287.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 53858.7812\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 10425.0918\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 3029.6831\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2116.5825\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 5ms/step - loss: 1601.1199\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1780.0931\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1237.8481\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2147.5911\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2105.1746\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3070084.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 6330.1924\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1818.5710\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1009.3735\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 328.0668\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 532.5611\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 628.7991\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 823.0380\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 228.6787\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 263.1840\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2168174.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8914.9727\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1391.8629\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 375.5193\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 150.3357\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 78.5191\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 704.1335\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 78.9654\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 33.7952\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 13.2864\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 47230054547062784.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0881\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.9540\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8286\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.7122\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6052\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5073\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4184\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3382\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.2661\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 35670601041444864.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0880\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.9539\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8285\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7120\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6049\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5069\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4180\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3378\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2658\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 46175034485506048.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0881\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9541\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8289\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7125\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6052\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5073\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4185\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 1.3382\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2663\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3382007881963405312.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0092\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7807\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6908\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6417\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6086\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5839\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5646\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5493\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5369\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5027686242796437504.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0094\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7806\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6904\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6412\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6081\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5835\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5643\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5489\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5365\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 225037010497175552.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0115\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7817\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6911\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6416\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6085\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5838\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5645\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5492\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5368\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 395239933008150528.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2586\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2290\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1995\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1704\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1416\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1133\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0852\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0574\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0300\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 6ms/step - loss: 483101082550009856.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2587\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2289\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1995\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.1704\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1416\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1132\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0850\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0573\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0299\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 593437967750529024.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2587\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2290\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1997\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1706\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1418\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.1134\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.0853\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0575\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.0301\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3755625167192064.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4680488929198080.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2767576262246400.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 50062259061260288.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0882\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9541\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8287\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7123\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6052\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5074\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4185\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3382\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2662\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 89846145987117056.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0881\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9539\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8286\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7120\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6050\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5069\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4180\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3379\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2658\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 52728682132799488.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0880\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9540\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8288\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7124\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6051\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5072\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4184\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3382\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2662\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3452892297094496256.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0092\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7807\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6908\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6417\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6086\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5839\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5646\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5493\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5369\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7535136803590766592.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0094\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7806\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6904\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6412\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6081\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5835\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5643\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5489\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5365\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7497072810548789248.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.0100\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7812\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6909\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6415\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6084\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5838\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5645\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5491\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5367\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 45884788.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 230750.8750\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 245614.8750\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 188188.8750\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 234612.6250\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 114468.9375\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 277456.1562\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 260906.8906\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 254571.9219\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 198925.2812\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 1612382.1250\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 187331.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 233102.7344\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 267362.2188\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 147381.7812\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 117813.7031\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 153394.3281\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 206766.5938\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 153798.1094\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 255068.1094\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 53899464.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 7073312.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 133251.4531\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 220272.3438\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 126494.4531\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 136387.3750\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 198313.1250\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 217976.5312\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 218604.5469\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 189527.8125\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 73891352.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8456757.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7351900.5000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5988676.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5022712.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4160671.7500\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3352287.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2876670.7500\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2098464.2500\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1757267.2500\n",
      "40/40 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 17299706.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 11952747.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9460383.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7261968.5000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5478559.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4252489.5000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3251870.5000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2386841.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1553514.8750\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1030963.1875\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 51920244.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 10812727.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8680513.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7531356.5000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 6247909.5000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4927777.5000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3594324.2500\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2591941.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1868311.1250\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1256703.0000\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 25054138.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1676719.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1502796.3750\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1074561.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 868972.0625\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1481720.1250\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 797631.0625\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 884415.4375\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 551641.3125\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 426742.3125\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 9302536.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4222338.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1889796.2500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1721368.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6942149.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2242012.0000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2303336.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1789607.8750\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2233864.2500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1303791.8750\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 33911036.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7871759.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 3598176.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3380047.2500\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4090175.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1736561.1250\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1285419.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1094929.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 479439.6875\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1193474.6250\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 4625465647902490624.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8470\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8492\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8328\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8551\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8375\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8459\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.8252\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8417\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8311\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 11872407809469448192.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8407\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8389\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8406\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8383\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8265\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8334\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8283\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.8314\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.8326\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 11205464946781454336.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5761\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5574\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5588\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5496\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5519\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.5466\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5381\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5391\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5347\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2267249.2500\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 172044.1562\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 142633.4688\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 133527.3594\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 149926.0781\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 133485.2500\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 211444.2031\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 128142.5859\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 254625.9219\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 200046.1406\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 5654930.5000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 182655.0469\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 200953.0625\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 237535.6562\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 228316.7500\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 174656.1875\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 249106.2812\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 184862.9375\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 149159.6562\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 213789.7969\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2960834.7500\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 231348.6250\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 256454.1406\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 266130.0625\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 303422.1875\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 221095.0312\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 242072.1562\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 263883.6875\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 221237.8594\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 250333.0000\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2192846421491712.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0883\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9541\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8288\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7124\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6053\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5074\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4185\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3383\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2662\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2209818655850496.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0882\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9540\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8286\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7121\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6050\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5070\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4181\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3379\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2659\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2272669596647424.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.0881\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.9541\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.8289\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.7125\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.6053\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.5073\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4185\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.3383\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.2663\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 43128893355327488000.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8950\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.6590\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4601\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2978\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1684\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.0667\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9864\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9231\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.8727\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 46139954326503686144.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8962\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6599\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.4612\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.2985\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1688\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.0667\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9864\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.9233\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.8729\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 50060452151338991616.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8957\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.6592\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.4615\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2988\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1.1690\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0668\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9867\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9231\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.8728\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 443487082250240.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2804\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2656\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2509\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2362\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2216\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2071\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1927\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1783\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1640\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 493462784835584.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2803\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2655\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2508\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2361\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2215\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2070\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1926\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1782\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1639\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 550038543532032.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2803\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2655\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2508\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2362\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2216\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.2071\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1926\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1783\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2.1640\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 30223310.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9750990.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8633377.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8345817.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7929988.5000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7396121.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6640234.5000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6479002.5000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5714334.5000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5496848.0000\n",
      "119/119 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 2s 3ms/step - loss: 57414732.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 12101021.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 10753514.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 10630764.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9898961.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9396493.0000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9452772.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9007921.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8652435.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7837896.0000\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 31963590.0000\n",
      "Epoch 2/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 10324553.0000\n",
      "Epoch 3/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9527862.0000\n",
      "Epoch 4/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8429519.0000\n",
      "Epoch 5/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 8192846.0000\n",
      "Epoch 6/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7558430.5000\n",
      "Epoch 7/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7467572.0000\n",
      "Epoch 8/10\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 7015709.0000\n",
      "Epoch 9/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6886782.0000\n",
      "Epoch 10/10\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6460690.0000\n",
      "119/119 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 33892320.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1259846.7500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 898918.5625\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 749472.6250\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1013974.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 455020.9688\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 409649.9688\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 339449.0000\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 614117.0625\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 729289.8125\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 12980807.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1093723.1250\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 650780.6875\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 678608.0625\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 726648.6875\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 688681.6875\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 272425.1875\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 268787.4688\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 276954.4375\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 602296.1875\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 12750377.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1145542.1250\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 986466.3750\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 739484.3125\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 814985.0000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 288741.2812\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 468476.5938\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 931484.5625\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 880847.1250\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 758733.0000\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 10733158.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 5786660.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3593428.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2400343.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1563396.3750\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 979353.5000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 596190.1250\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 340509.0625\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 205321.0938\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 110813.3281\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 7ms/step - loss: 25010852.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 7063578.5000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4275203.5000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3225145.7500\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 2203034.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 1614190.7500\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1048559.6250\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 716732.3125\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 424452.7812\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 245568.6875\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 21740372.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 7207777.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 4879061.0000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 3580854.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2617665.5000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1918064.5000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 1312056.7500\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 978155.3125\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 642092.6250\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 375232.6250\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 201982463705088.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2952\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 3560957921984512.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 4367967512952832.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2982\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2951\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2921\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2891\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2861\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2831\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2801\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2771\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2741\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 180666784.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 91250984.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 13197938.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 102918.7812\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 82813.0547\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 72821.6641\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 39904.4531\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 63062.7070\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 79199.8750\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 75626.4375\n",
      "40/40 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 18165134.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5984823.5000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 119048.4375\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 68982.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 51594.5547\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 59721.7656\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 71321.8594\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 70438.8125\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 36369.8203\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 29275.3340\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 25391662.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 15124869.0000\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6425255.0000\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 348779.8125\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 112119.0625\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 64311.3203\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 85405.5234\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 85373.1328\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 81655.3594\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 73805.7422\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 1438367770214400.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2903\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2853\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2803\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2754\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2705\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2655\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2606\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2557\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 1405355443617792.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2902\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2853\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2803\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2754\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2704\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2655\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2606\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2557\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 1499472672587776.0000\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2952\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2903\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2853\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2803\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2754\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2705\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2655\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2606\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2557\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 22460900.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3708275.2500\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2313240.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2872623.2500\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2737914.5000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1793676.1250\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1942267.8750\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1470137.6250\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1344574.7500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1097096.3750\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 18227742.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6053909.0000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2529792.5000\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4951922.5000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3580856.5000\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2553579.5000\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4368070.5000\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3130908.2500\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2619686.2500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2553690.7500\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 3ms/step - loss: 35934028.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1559343.5000\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2754952.7500\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3757329.0000\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3190763.7500\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2068024.7500\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1902734.1250\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 3763660.2500\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1315122.7500\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 893295.3125\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 28669196147236012032.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3171\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3130\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.3088\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3047\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3005\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2964\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2923\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.2881\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2840\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 5ms/step - loss: 61552041909504966656.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.7607\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.7343\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7275\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7253\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7246\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7243\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7241\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.7239\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.7237\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 4ms/step - loss: 70106990041509134336.0000\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3133\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.3097\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 2.3061\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.3025\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2989\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2953\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2917\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 2.2881\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 2.2846\n",
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 276, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 73, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 256, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\pipeline.py\", line 686, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1442, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels.astype(\"int64\", copy=False)]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 2\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.83987022 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022\n",
      " 0.83987022 0.83987022 0.83987022 0.61322613 0.698888   0.83987022\n",
      " 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022\n",
      " 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022\n",
      " 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022\n",
      " 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022 0.83987022\n",
      " 0.83987022 0.83987022 0.61346311 0.83987022 0.83987022 0.83987022\n",
      " 0.83987022 0.83987022 0.83987022 0.83987022 0.61322613 0.83987022\n",
      " 0.61322613        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 11434167701832722284544.0000\n",
      "Epoch 2/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.9163\n",
      "Epoch 3/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.9170\n",
      "Epoch 4/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.9184\n",
      "Epoch 5/10\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 0.9069\n",
      "Epoch 6/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.8999\n",
      "Epoch 7/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.9188\n",
      "Epoch 8/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.9056\n",
      "Epoch 9/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.8843\n",
      "Epoch 10/10\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 0.8760\n",
      "CPU times: total: 1h 21min 39s\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='accuracy',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=50, \n",
    "    cv=3)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)\n",
    "\n",
    "# You can create 'call back' functions. These are functions that will be called at the \n",
    "# end of each epoch. There are a number of builtin functions created for this purpose, \n",
    "# one of which is EarlyStopping -- that, based on the parameters you give, will stop\n",
    "# the training process. This is useful when the algorithm is not making any significant\n",
    "# gains through further training. \n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "#callback = [earlystop]\n",
    "#_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.001,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (100, 90),\n",
       " 'model__dropout': 0.1,\n",
       " 'loss': 'sparse_categorical_crossentropy',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 60}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.830     0.675     0.745      2547\n",
      "           1      0.146     0.287     0.193       492\n",
      "\n",
      "    accuracy                          0.612      3039\n",
      "   macro avg      0.488     0.481     0.469      3039\n",
      "weighted avg      0.720     0.612     0.655      3039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test_s), digits=3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier and Keras Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that we don't predict churning as non-churning customers. That's why the model needs to be evaluated on the \"Recall\"- metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall values all alogorithms\n",
    "* MLP Classifier = 77%\n",
    "* MLP classifier with random search = 69%\n",
    "* keras with random search = 28%\n",
    "* Logistic Regression =57%\n",
    "* Decision tree = 84%\n",
    "* Random Forest Classifier = 89%\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is less computationally expensive and does not require a GPU to finish training. A random forest can give you a different interpretation of a decision tree but with better performance. Neural Networks will require much more data than an everyday person might have on hand to actually be effective. The neural network will simply decimate the interpretability of your features to the point where it becomes meaningless for the sake of performance. While that may sound reasonable to some, it is dependent on each project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
