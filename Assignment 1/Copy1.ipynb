{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let us load the required data into individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/suman/DspData/data/churn_train_X.csv') \n",
    "y_train = pd.read_csv('C:/Users/suman/DspData/data/churn_train_y.csv') \n",
    "X_test = pd.read_csv('C:/Users/suman/DspData/data/churn_test_X.csv') \n",
    "y_test = pd.read_csv('C:/Users/suman/DspData/data/churn_test_y.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a data frame called performance and put all the needed metrics in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 8 is smaller than n_iter=500. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "The best recall score is 0.5669050216135417\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.         0.56690502 0.         0.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan 0.         0.56917868 0.         0.\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['None','l1','l2','elasticnet'],\n",
    "    'solver':['saga','liblinear']\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.5695996444875369\n",
      "... with parameters: {'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "penalty = rand_search.best_params_['penalty']\n",
    "solver = rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {  \n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallLogistic = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.57393</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision   Recall        F1\n",
       "0  Logistic Regression  0.903587   0.799458  0.57393  0.668177"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression\",\n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "print(TP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Linear) - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset (only training data)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_up, y_up = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "     'C':[1,100,1000],\n",
    "    'gamma':[0,10,100],\n",
    "'kernel':['linear']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=3,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_up, y_up)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (RBF) - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.001, 0.10, 0.0001,0.00001],   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['rbf']\n",
    "}\n",
    "\n",
    "model = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=3,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_up, y_up)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best SVM recall I observed : 77%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: I tried to run SVM model for 7 hours and didnt got any results. May be I'm using too many training examples for SVM implementation.Overall, SVMs can be slow to train because of their complexity, particularly when working with large datasets or high-dimensional data. However, the trade-off is that SVMs are often very accurate and effective for a wide range of classification problems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees - Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.7861754130812427\n",
      "... with parameters: {'min_samples_split': 19, 'min_samples_leaf': 15, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 66, 'max_depth': 11, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,100),  \n",
    "    'min_samples_leaf': np.arange(1,75),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 80), \n",
    "    'max_depth': np.arange(1,40), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE - GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "The best recall score is 0.7969862238920535\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 10, 'max_leaf_nodes': 65, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 13, 'min_samples_split': 17}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.573930</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.826004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.903587   0.799458  0.573930  0.668177\n",
       "0        Decision Tree  0.940112   0.812030  0.840467  0.826004"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, for this assignment we have to use Logistic Regression, SVM, and Decision tree. But the dataset is best suited for Random Forest Algorithm (From the dataset website) and  It's important that we don't predict churning as non-churning customers. That's why the model needs to be evaluated on the \"Recall\"- metric (goal > 77%). And also I tried to Upsample the imbalanced dataset using SMOTE Technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset (only training data)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_up, y_up = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_7920\\1298015926.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_up, y_up)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_up, y_up)\n",
    "\n",
    "rfpred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>0.573930</td>\n",
       "      <td>0.668177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.840467</td>\n",
       "      <td>0.826004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.945048</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.896887</td>\n",
       "      <td>0.846648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  Accuracy  Precision    Recall        F1\n",
       "0       Logistic Regression  0.903587   0.799458  0.573930  0.668177\n",
       "0             Decision Tree  0.940112   0.812030  0.840467  0.826004\n",
       "0  Random Forest Classifier  0.945048   0.801739  0.896887  0.846648"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = (confusion_matrix(y_test, rfpred))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest Classifier\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "print(TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.16 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 8.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      2547\n",
      "           1       0.00      0.00      0.00       492\n",
      "\n",
      "    accuracy                           0.84      3039\n",
      "   macro avg       0.42      0.50      0.46      3039\n",
      "weighted avg       0.70      0.84      0.76      3039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.5, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (40, 20), 'alpha': 0.2, 'activation': 'tanh'}\n",
      "CPU times: total: 5.31 s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      2547\n",
      "           1       0.00      0.00      0.00       492\n",
      "\n",
      "    accuracy                           0.84      3039\n",
      "   macro avg       0.42      0.50      0.46      3039\n",
      "weighted avg       0.70      0.84      0.76      3039\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 23.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (30,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      2525\n",
      "           1       0.00      0.00      0.00       514\n",
      "\n",
      "    accuracy                           0.83      3039\n",
      "   macro avg       0.42      0.50      0.45      3039\n",
      "weighted avg       0.69      0.83      0.75      3039\n",
      "\n",
      "Wall time: 16.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\suman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks, particularly deep neural networks, have shown to be effective in various machine learning tasks, including classification, regression, and pattern recognition. When it comes to recall, which is a measure of a model's ability to correctly identify positive cases out of all actual positive cases, neural networks have certain advantages that can make them perform better than other models.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While comparing all other models and neural networks we got better recall value for neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, while other models like logistic regression or decision trees can also achieve good recall, neural networks have certain advantages that can make them perform better in certain cases. However, it's important to note that the performance of a neural network depends on several factors, including the choice of architecture, training algorithm, and hyperparameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion :The goal of this project is to provide an analysis which shows the difference between a non-churning and churning customer. Using the existing data managed to train a model with upsampled data which reaches a recall score of 89%.This will provide us insight into which customers are eager to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s, X_test_s = scaler.transform(X_train), scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suman\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.44862317\n",
      "Validation score: 0.839210\n",
      "Iteration 2, loss = 0.33535280\n",
      "Validation score: 0.889986\n",
      "Iteration 3, loss = 0.27574681\n",
      "Validation score: 0.901269\n",
      "Iteration 4, loss = 0.24173369\n",
      "Validation score: 0.911142\n",
      "Iteration 5, loss = 0.21827064\n",
      "Validation score: 0.913963\n",
      "Iteration 6, loss = 0.20203913\n",
      "Validation score: 0.918195\n",
      "Iteration 7, loss = 0.18582558\n",
      "Validation score: 0.916784\n",
      "Iteration 8, loss = 0.17523539\n",
      "Validation score: 0.921016\n",
      "Iteration 9, loss = 0.16345759\n",
      "Validation score: 0.921016\n",
      "Iteration 10, loss = 0.15401486\n",
      "Validation score: 0.930889\n",
      "Iteration 11, loss = 0.14891844\n",
      "Validation score: 0.923836\n",
      "Iteration 12, loss = 0.14117642\n",
      "Validation score: 0.918195\n",
      "Iteration 13, loss = 0.13372900\n",
      "Validation score: 0.923836\n",
      "Iteration 14, loss = 0.13044018\n",
      "Validation score: 0.923836\n",
      "Iteration 15, loss = 0.12451411\n",
      "Validation score: 0.923836\n",
      "Iteration 16, loss = 0.11883957\n",
      "Validation score: 0.921016\n",
      "Validation score did not improve more than tol=0.000010 for 5 consecutive epochs. Stopping.\n",
      "CPU times: total: 2.47 s\n",
      "Wall time: 749 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(60,50,40), \n",
    "    activation = 'relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001, # Strength of the L2 regularization term\n",
    "    batch_size='auto',\n",
    "    learning_rate = 'constant',\n",
    "    learning_rate_init = 0.001,\n",
    "    max_iter=200,\n",
    "    tol=0.00001, \n",
    "    early_stopping = True,\n",
    "    n_iter_no_change = 5,\n",
    "    verbose=True\n",
    "    \n",
    ")\n",
    "_ = model1.fit(X_train_s, y_train)\n",
    "\n",
    "# Currently (version 1.2.2), MLPClassifier supports only the Cross-Entropy loss function.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4486231731885894,\n",
       " 0.3353528008513056,\n",
       " 0.27574681278677426,\n",
       " 0.24173368866603048,\n",
       " 0.2182706363561413,\n",
       " 0.20203913171992582,\n",
       " 0.18582557876444797,\n",
       " 0.17523538872958033,\n",
       " 0.1634575870934346,\n",
       " 0.15401485852424174,\n",
       " 0.14891844172867955,\n",
       " 0.1411764174871404,\n",
       " 0.13372900069928326,\n",
       " 0.13044018198183993,\n",
       " 0.12451410809483643,\n",
       " 0.11883957294582763]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9330    0.9780    0.9550      2547\n",
      "           1     0.8482    0.6362    0.7271       492\n",
      "\n",
      "    accuracy                         0.9227      3039\n",
      "   macro avg     0.8906    0.8071    0.8410      3039\n",
      "weighted avg     0.9192    0.9227    0.9181      3039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "y_train_pred, y_test_pred = (model1.predict(X_train_s).flatten() > 0.5)*1, (model1.predict(X_test_s).flatten() > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kears</td>\n",
       "      <td>0.936371</td>\n",
       "      <td>0.855509</td>\n",
       "      <td>0.725110</td>\n",
       "      <td>0.784931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kears</td>\n",
       "      <td>0.940745</td>\n",
       "      <td>0.870466</td>\n",
       "      <td>0.740088</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.940745</td>\n",
       "      <td>0.870466</td>\n",
       "      <td>0.740088</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  Accuracy  Precision    Recall        F1\n",
       "0  kears  0.936371   0.855509  0.725110  0.784931\n",
       "0  kears  0.940745   0.870466  0.740088  0.800000\n",
       "0    MLP  0.940745   0.870466  0.740088  0.800000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"MLP\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "222/222 [==============================] - 2s 4ms/step - loss: 0.5495 - val_loss: 0.3649\n",
      "Epoch 2/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.3224 - val_loss: 0.2689\n",
      "Epoch 3/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2757 - val_loss: 0.2568\n",
      "Epoch 4/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2652 - val_loss: 0.2495\n",
      "Epoch 5/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2583 - val_loss: 0.2448\n",
      "Epoch 6/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2547 - val_loss: 0.2430\n",
      "Epoch 7/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2490 - val_loss: 0.2393\n",
      "Epoch 8/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2510 - val_loss: 0.2380\n",
      "Epoch 9/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 0.2460 - val_loss: 0.2356\n",
      "Epoch 10/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2408 - val_loss: 0.2334\n",
      "Epoch 11/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2434 - val_loss: 0.2301\n",
      "Epoch 12/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2402 - val_loss: 0.2280\n",
      "Epoch 13/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2341 - val_loss: 0.2263\n",
      "Epoch 14/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2393 - val_loss: 0.2252\n",
      "Epoch 15/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2337 - val_loss: 0.2242\n",
      "Epoch 16/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2276 - val_loss: 0.2219\n",
      "Epoch 17/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2291 - val_loss: 0.2199\n",
      "Epoch 18/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2276 - val_loss: 0.2186\n",
      "Epoch 19/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2304 - val_loss: 0.2175\n",
      "Epoch 20/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2208 - val_loss: 0.2164\n",
      "Epoch 21/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2228 - val_loss: 0.2160\n",
      "Epoch 22/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2246 - val_loss: 0.2123\n",
      "Epoch 23/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2215 - val_loss: 0.2108\n",
      "Epoch 24/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 0.2172 - val_loss: 0.2109\n",
      "Epoch 25/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2174 - val_loss: 0.2067\n",
      "Epoch 26/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2184 - val_loss: 0.2072\n",
      "Epoch 27/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2161 - val_loss: 0.2042\n",
      "Epoch 28/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2137 - val_loss: 0.2074\n",
      "Epoch 29/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2116 - val_loss: 0.2020\n",
      "Epoch 30/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2069 - val_loss: 0.2034\n",
      "Epoch 31/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2058 - val_loss: 0.2004\n",
      "Epoch 32/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2071 - val_loss: 0.1968\n",
      "Epoch 33/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2066 - val_loss: 0.1966\n",
      "Epoch 34/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2049 - val_loss: 0.1962\n",
      "Epoch 35/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2043 - val_loss: 0.1934\n",
      "Epoch 36/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2011 - val_loss: 0.1959\n",
      "Epoch 37/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2047 - val_loss: 0.1933\n",
      "Epoch 38/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2066 - val_loss: 0.1928\n",
      "Epoch 39/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2029 - val_loss: 0.1905\n",
      "Epoch 40/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1996 - val_loss: 0.1895\n",
      "Epoch 41/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1981 - val_loss: 0.1896\n",
      "Epoch 42/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1990 - val_loss: 0.1888\n",
      "Epoch 43/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1963 - val_loss: 0.1891\n",
      "Epoch 44/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1910 - val_loss: 0.1887\n",
      "Epoch 45/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1997 - val_loss: 0.1886\n",
      "Epoch 46/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2009 - val_loss: 0.1859\n",
      "Epoch 47/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1943 - val_loss: 0.1848\n",
      "Epoch 48/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1945 - val_loss: 0.1886\n",
      "Epoch 49/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1958 - val_loss: 0.1856\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcnUlEQVR4nO3deXhU9cH+//dMkpnsC2QPgYRFFjVEWSLiThDUWrT2EVtbllpstVr7UH4uTyuI2sbta1GhYq27taK2am0tqKlgEQRkEWSTJRBC9kAyWcg2c35/nGRCTEIy2SaB+3Vd55rJ2eYzJ9Tc/awWwzAMRERERPoZq7cLICIiItIZCjEiIiLSLynEiIiISL+kECMiIiL9kkKMiIiI9EsKMSIiItIvKcSIiIhIv6QQIyIiIv2Sr7cL0B1cLhe5ubmEhIRgsVi8XRwRERHpAMMwKC8vJz4+HqvV83qV0yLE5ObmkpiY6O1iiIiISCccOXKEQYMGeXzdaRFiQkJCAPMhhIaGerk0IiIi0hEOh4PExET333FPnRYhprEJKTQ0VCFGRESkn+lsVxB17BUREZF+SSFGRERE+iWFGBEREemXTos+MSIicvpwOp3U1dV5uxjSTfz8/PDx8emReyvEiIhIn1FRUUFOTg6GYXi7KNJNLBYLgwYNIjg4uNvvrRAjIiJ9gtPpJCcnh8DAQKKiojR56WnAMAyKiorIyclhxIgR3V4joxAjIiJ9Ql1dHYZhEBUVRUBAgLeLI90kKiqKQ4cOUVdX1+0hRh17RUSkT1ENzOmlJ3+fCjEiIiLSL3UqxCxbtoykpCT8/f1JS0tj48aNbZ778ssvY7FYmm3+/v7NzpkzZ06Lc6ZPn96ZoomIiPRbSUlJLFmypMPnr169GovFQmlpaY+VqS/zuE/MihUrmD9/PsuXLyctLY0lS5Ywbdo09u7dS3R0dKvXhIaGsnfvXvfPrVUtTZ8+nZdeesn9s91u97RoIiIive6yyy4jNTXVo/DRlk2bNhEUFNTh8y+88ELy8vIICwvr8mf3Rx6HmCeffJJ58+Yxd+5cAJYvX86//vUvXnzxRe69995Wr7FYLMTGxp7yvna7vd1zRERE+hvDMHA6nfj6tv8nNyoqyqN722y2M/pvp0fNSbW1tWzevJn09PSmG1itpKens379+javq6ioYMiQISQmJjJjxgx27tzZ4pzVq1cTHR3NyJEjue222ygpKWnzfjU1NTgcjmZbTyh0VPPwP3eR8e/dPXJ/ERHp3+bMmcOaNWt46qmn3N0hGrtR/Pvf/2bcuHHY7XbWrl3LgQMHmDFjBjExMQQHBzNhwgQ++eSTZvf7dnOSxWLhz3/+M9dffz2BgYGMGDGCf/zjH+7j325OevnllwkPD2fVqlWMHj2a4OBgpk+fTl5envua+vp6fvnLXxIeHs7AgQO55557mD17Ntddd11PPqoe4VGIKS4uxul0EhMT02x/TEwM+fn5rV4zcuRIXnzxRd5//31ef/11XC4XF154ITk5Oe5zpk+fzquvvkpmZiaPPvooa9as4aqrrsLpdLZ6z4yMDMLCwtxbYmKiJ1+jw8pr6vnz2ize2JDdI/cXEZG2GYZBVW29V7aOTrb31FNPMWnSJObNm0deXh55eXnuv0n33nsvjzzyCLt37yYlJYWKigquvvpqMjMz2bp1K9OnT+faa68lO/vUf2MWL17MjTfeyPbt27n66qu5+eabOXbsWJvnV1VV8cQTT/Daa6/x2WefkZ2dzYIFC9zHH330Uf7yl7/w0ksv8fnnn+NwOHjvvfc69H37mh6fJ2bSpElMmjTJ/fOFF17I6NGjee6553jooYcAuOmmm9zHzz33XFJSUhg2bBirV69mypQpLe553333MX/+fPfPDoejR4JMoM0cz36itvUwJSIiPedEnZMxC1d55bN3PTiNQFv7fyLDwsKw2WwEBga6m3X27NkDwIMPPsjUqVPd5w4YMICxY8e6f37ooYd49913+cc//sEdd9zR5mfMmTOHH/zgBwD8/ve/5+mnn2bjxo1tDoCpq6tj+fLlDBs2DIA77riDBx980H38mWee4b777uP6668HYOnSpXz44Yftfte+yKOamMjISHx8fCgoKGi2v6CgoMNtcn5+fpx33nns37+/zXOGDh1KZGRkm+fY7XZCQ0ObbT2h8R9wvcugtt7VI58hIiKnp/Hjxzf7uaKiggULFjB69GjCw8MJDg5m9+7d7dbEpKSkuN8HBQURGhpKYWFhm+cHBga6AwxAXFyc+/yysjIKCgqYOHGi+7iPjw/jxo3z6Lv1FR7VxNhsNsaNG0dmZqa77czlcpGZmXnKFHkyp9PJjh07uPrqq9s8Jycnh5KSEuLi4jwpXrdrrIkBqKqtx+Zr82JpRETOLAF+Pux6cJrXPrurvj3KaMGCBXz88cc88cQTDB8+nICAAL7//e9TW1t7yvv4+fk1+9liseBytf1/rFs7/3Rdi8rj5qT58+cze/Zsxo8fz8SJE1myZAmVlZXu0UqzZs0iISGBjIwMwKxOu+CCCxg+fDilpaU8/vjjHD58mJ/+9KeAmUwXL17MDTfcQGxsLAcOHODuu+9m+PDhTJvmnX+8jfx8rNh8rNQ6XVTVOgkP9GpxRETOKBaLpUNNOt5ms9na7MN5ss8//5w5c+a4m3EqKio4dOhQD5euubCwMGJiYti0aROXXHIJYFYubNmyhdTU1F4tS3fw+F/HzJkzKSoqYuHCheTn55OamsrKlSvdnX2zs7OxWptaqY4fP868efPIz88nIiKCcePGsW7dOsaMGQOY1Vjbt2/nlVdeobS0lPj4eK688koeeuihPjFXTIDNh9oTLqpq671dFBER6YOSkpLYsGEDhw4dIjg4uM1akhEjRvD3v/+da6+9FovFwv3333/KGpWecuedd5KRkcHw4cMZNWoUzzzzDMePH++Xyz10KuLecccdbTYfrV69utnPf/jDH/jDH/7Q5r0CAgJYtco7Hbc6IsjmQ9mJOqrUuVdERFqxYMECZs+ezZgxYzhx4kSziVtP9uSTT/KTn/yECy+8kMjISO65554emyLkVO655x7y8/OZNWsWPj4+3HrrrUybNq3bF2fsDRbjNGgoczgchIWFUVZW1u2dfKf8v9UcKKrkr/MuYNKwgd16bxERaVJdXU1WVhbJycktlqeRnuNyuRg9ejQ33nije9RwdzrV77Wrf7/7fmOjlwXZzUd0ok7NSSIi0v8dPnyYjz76iEsvvZSamhqWLl1KVlYWP/zhD71dNI9pFet2NPZQr6xRc5KIiPR/VquVl19+mQkTJjB58mR27NjBJ598wujRo71dNI+pJqYd7poY9YkREZHTQGJiIp9//rm3i9EtVBPTjoCGuWIqNTpJRESkT1GIaUdQQ4jR6CQREZG+RSGmHY0TLWmeGBERkb5FIaYdgaqJERER6ZMUYtrhDjEanSQiItKnKMS0w92cVKcQIyIi0pcoxLSjqSZGfWJERKRnJCUlsWTJEvfPFouF9957r83zDx06hMViYdu2bV363O66j7donph2BNobO/aqJkZERHpHXl4eERER3XrPOXPmUFpa2iwcJSYmkpeXR2RkZLd+Vm9RiGlHoF9jx17VxIiISO+IjY3tlc/x8fHptc/qCWpOakegXaOTRESkbX/605+Ij4/H5XI12z9jxgx+8pOfcODAAWbMmEFMTAzBwcFMmDCBTz755JT3/HZz0saNGznvvPPw9/dn/PjxbN26tdn5TqeTW265heTkZAICAhg5ciRPPfWU+/gDDzzAK6+8wvvvv4/FYsFisbB69epWm5PWrFnDxIkTsdvtxMXFce+991Jf3/R/5C+77DJ++ctfcvfddzNgwABiY2N54IEHPH9w3UA1Me1omidGIUZEpFcZBtRVeeez/QLBYunQqf/zP//DnXfeyaeffsqUKVMAOHbsGCtXruTDDz+koqKCq6++mt/97nfY7XZeffVVrr32Wvbu3cvgwYPbvX9FRQXf+c53mDp1Kq+//jpZWVncddddzc5xuVwMGjSIt99+m4EDB7Ju3TpuvfVW4uLiuPHGG1mwYAG7d+/G4XDw0ksvATBgwAByc3Ob3efo0aNcffXVzJkzh1dffZU9e/Ywb948/P39mwWVV155hfnz57NhwwbWr1/PnDlzmDx5MlOnTu3QM+suCjHtaJqxV81JIiK9qq4Kfh/vnc/+v1ywBXXo1IiICK666ireeOMNd4h55513iIyM5PLLL8dqtTJ27Fj3+Q899BDvvvsu//jHP7jjjjvavf8bb7yBy+XihRdewN/fn7PPPpucnBxuu+029zl+fn4sXrzY/XNycjLr16/nrbfe4sYbbyQ4OJiAgABqampO2Xz0xz/+kcTERJYuXYrFYmHUqFHk5uZyzz33sHDhQqxWswEnJSWFRYsWATBixAiWLl1KZmZmr4cYNSe1o2ntJNXEiIhI626++Wb+9re/UVNTA8Bf/vIXbrrpJqxWKxUVFSxYsIDRo0cTHh5OcHAwu3fvJjs7u0P33r17NykpKfj7+7v3TZo0qcV5y5YtY9y4cURFRREcHMyf/vSnDn/GyZ81adIkLCfVQk2ePJmKigpycnLc+1JSUppdFxcXR2FhoUef1R1UE9OOoIbmpNp6F/VOF74+yn0iIr3CL9CsEfHWZ3vg2muvxTAM/vWvfzFhwgT++9//8oc//AGABQsW8PHHH/PEE08wfPhwAgIC+P73v09tbW23FffNN99kwYIF/L//9/+YNGkSISEhPP7442zYsKHbPuNkfn5+zX62WCwt+gT1BoWYdjTWxIA54V2oQoyISO+wWDrcpONt/v7+fO973+Mvf/kL+/fvZ+TIkZx//vkAfP7558yZM4frr78eMPu4HDp0qMP3Hj16NK+99hrV1dXu2pgvvvii2Tmff/45F154Ibfffrt734EDB5qdY7PZcDpP3aowevRo/va3v2EYhrs25vPPPyckJIRBgwZ1uMy9RX+R22H3teJjNX+RJ9SkJCIibbj55pv517/+xYsvvsjNN9/s3j9ixAj+/ve/s23bNr766it++MMfelRr8cMf/hCLxcK8efPYtWsXH374IU888USzc0aMGMGXX37JqlWr+Oabb7j//vvZtGlTs3OSkpLYvn07e/fupbi4mLq6uhafdfvtt3PkyBHuvPNO9uzZw/vvv8+iRYuYP3++uz9MX9L3StTHWCwW91wxlZq1V0RE2nDFFVcwYMAA9u7dyw9/+EP3/ieffJKIiAguvPBCrr32WqZNm+aupemI4OBgPvjgA3bs2MF5553Hb37zGx599NFm5/zsZz/je9/7HjNnziQtLY2SkpJmtTIA8+bNY+TIkYwfP56oqCg+//zzFp+VkJDAhx9+yMaNGxk7diw///nPueWWW/jtb3/r4dPoHRbDMAxvF6KrHA4HYWFhlJWVERoa2u33T/v9JxQ4avjnnRdxTkJYt99fRESgurqarKwskpOTm3Vilf7tVL/Xrv79Vk1MB2iuGBERkb5HIaYDAjVXjIiISJ+jENMBTSFGNTEiIiJ9hUJMB6g5SUREpO9RiOkANSeJiIj0PQoxHaCaGBGR3nMaDJqVk/Tk71MhpgPcNTGaJ0ZEpMf4+Jj/re3O6fjF+xp/n42/3+6kZQc6INCujr0iIj3N19eXwMBAioqK8PPz65MzxIpnXC4XRUVFBAYG4uvb/ZFDIaYDAv3Mx6SVrEVEeo7FYiEuLo6srCwOHz7s7eJIN7FarQwePLjZytjdRSGmA4IaamJOqGOviEiPstlsjBgxQk1KpxGbzdZjtWoKMR3QuJK1amJERHqe1WrVsgPSIWpw7ICghtFJWsVaRESk71CI6YCmmhg1J4mIiPQVnQoxy5YtIykpCX9/f9LS0ti4cWOb57788stYLJZm27erCQ3DYOHChcTFxREQEEB6ejr79u3rTNF6hGpiRERE+h6PQ8yKFSuYP38+ixYtYsuWLYwdO5Zp06ZRWFjY5jWhoaHk5eW5t2/3On/sscd4+umnWb58ORs2bCAoKIhp06ZRXV3t+TfqAaqJERER6Xs8DjFPPvkk8+bNY+7cuYwZM4bly5cTGBjIiy++2OY1FouF2NhY9xYTE+M+ZhgGS5Ys4be//S0zZswgJSWFV199ldzcXN57771Ofanu1jQ6STUxIiIifYVHIaa2tpbNmzeTnp7edAOrlfT0dNavX9/mdRUVFQwZMoTExERmzJjBzp073ceysrLIz89vds+wsDDS0tLavGdNTQ0Oh6PZ1pPc88TUKMSIiIj0FR6FmOLiYpxOZ7OaFICYmBjy8/NbvWbkyJG8+OKLvP/++7z++uu4XC4uvPBCcnJyANzXeXLPjIwMwsLC3FtiYqInX8NjjTP2nqhz4nJpTQ8REZG+oMdHJ02aNIlZs2aRmprKpZdeyt///neioqJ47rnnOn3P++67j7KyMvd25MiRbixxS41rJ4EZZERERMT7PAoxkZGR+Pj4UFBQ0Gx/QUEBsbGxHbqHn58f5513Hvv37wdwX+fJPe12O6Ghoc22nuTv60PjbMlaP0lERKRv8CjE2Gw2xo0bR2Zmpnufy+UiMzOTSZMmdegeTqeTHTt2EBcXB0BycjKxsbHN7ulwONiwYUOH79nTrFYLAX6Ni0BqhJKIiEhf4PGyA/Pnz2f27NmMHz+eiRMnsmTJEiorK5k7dy4As2bNIiEhgYyMDAAefPBBLrjgAoYPH05paSmPP/44hw8f5qc//Slgjlz61a9+xcMPP8yIESNITk7m/vvvJz4+nuuuu677vmkXBdp8qap1qiZGRESkj/A4xMycOZOioiIWLlxIfn4+qamprFy50t0xNzs7u9lCT8ePH2fevHnk5+cTERHBuHHjWLduHWPGjHGfc/fdd1NZWcmtt95KaWkpF110EStXruxTa2c09otRTYyIiEjfYDEMo98Pt3E4HISFhVFWVtZj/WOmL/mMPfnlvHbLRC4eEdUjnyEiInIm6erfb62d1EGNNTGaK0ZERKRvUIjpoMDG9ZPq1JwkIiLSFyjEdJBqYkRERPoWhZgOagwxWj9JRESkb1CI6aBAe8P6SRqdJCIi0icoxHRQoJ9qYkRERPoShZgOUk2MiIhI36IQ00FNk92pJkZERKQvUIjpoKDGEKPRSSIiIn2CQkwHBTTME1NVpxAjIiLSFyjEdFBTTYz6xIiIiPQFCjEdFKA+MSIiIn2KQkwHBTWMTtIq1iIiIn2DQkwHBfipJkZERKQvUYjpoMaaGE12JyIi0jcoxHSQewHI2noMw/ByaUREREQhpoMaQ4zLgJp6l5dLIyIiIgoxHRTYME8MqF+MiIhIX6AQ00E+Vgt2X/NxaYSSiIiI9ynEeEDrJ4mIiPQdCjEeaGxSUogRERHxPoUYDwRq6QEREZE+QyHGA4F21cSIiIj0FQoxHgj0a5orRkRERLxLIcYDQXYzxGjWXhEREe9TiPFAQEPH3kqFGBEREa9TiPFAkK2xJkbNSSIiIt6mEOOBAPf6SaqJERER8TaFGA8E2bSStYiISF+hEOMBd02M5okRERHxOoUYDzT2iamqU02MiIiItynEeMC97IBqYkRERLxOIcYDgXYtACkiItJXKMR4QKtYi4iI9B0KMR5oWsVazUkiIiLe1qkQs2zZMpKSkvD39yctLY2NGzd26Lo333wTi8XCdddd12z/nDlzsFgszbbp06d3pmg9SjUxIiIifYfHIWbFihXMnz+fRYsWsWXLFsaOHcu0adMoLCw85XWHDh1iwYIFXHzxxa0enz59Onl5ee7tr3/9q6dF63FNNTEKMSIiIt7mcYh58sknmTdvHnPnzmXMmDEsX76cwMBAXnzxxTavcTqd3HzzzSxevJihQ4e2eo7dbic2Nta9RUREeFq0HtdUE6PmJBEREW/zKMTU1tayefNm0tPTm25gtZKens769evbvO7BBx8kOjqaW265pc1zVq9eTXR0NCNHjuS2226jpKSkzXNrampwOBzNtt7QOGNvndOgtt7VK58pIiIirfMoxBQXF+N0OomJiWm2PyYmhvz8/FavWbt2LS+88ALPP/98m/edPn06r776KpmZmTz66KOsWbOGq666Cqez9WabjIwMwsLC3FtiYqInX6PTGmfsBS09ICIi4m2+PXnz8vJyfvzjH/P8888TGRnZ5nk33XST+/25555LSkoKw4YNY/Xq1UyZMqXF+ffddx/z5893/+xwOHolyNh8rfj5WKhzGlTV1ROGX49/poiIiLTOoxATGRmJj48PBQUFzfYXFBQQGxvb4vwDBw5w6NAhrr32Wvc+l8tshvH19WXv3r0MGzasxXVDhw4lMjKS/fv3txpi7HY7drvdk6J3mwA/H+qc9VTWqCZGRETEmzxqTrLZbIwbN47MzEz3PpfLRWZmJpMmTWpx/qhRo9ixYwfbtm1zb9/97ne5/PLL2bZtW5u1Jzk5OZSUlBAXF+fh1+l5QXatZC0iItIXeNycNH/+fGbPns348eOZOHEiS5YsobKykrlz5wIwa9YsEhISyMjIwN/fn3POOafZ9eHh4QDu/RUVFSxevJgbbriB2NhYDhw4wN13383w4cOZNm1aF79e93OvZK0RSiIiIl7lcYiZOXMmRUVFLFy4kPz8fFJTU1m5cqW7s292djZWa8creHx8fNi+fTuvvPIKpaWlxMfHc+WVV/LQQw95rcnoVBpHKKkmRkRExLsshmEY3i5EVzkcDsLCwigrKyM0NLRHP+vG59azMesYS394Ht9Jie/RzxIRETmddfXvt9ZO8lCQlh4QERHpExRiPOReeqBGfWJERES8SSHGQ+6lB+pUEyMiIuJNCjEecocYzRMjIiLiVQoxHgq0ayVrERGRvkAhxkOBflrJWkREpC9QiPGQamJERET6BoUYD7n7xKgmRkRExKsUYjwUqHliRERE+gSFGA81zhNTqRAjIiLiVQoxHmqcsfeEmpNERES8SiHGQ+5VrDVPjIiIiFcpxHgoqGF00gnN2CsiIuJVCjEeCvBrrIlRc5KIiIg3KcR4qLEmpqbehdNleLk0IiIiZy6FGA81DrEGzRUjIiLiTQoxHrL7WrFazPcnNMxaRETEaxRiPGSxWDRXjIiISB+gENMJWnpARETE+xRiOkFLD4iIiHifQkwnBNi0krWIiIi3KcR0QuPSA1WaK0ZERMRrFGI6IUDNSSIiIl6nENMJQe7mJNXEiIiIeItCTCeoY6+IiIj3KcR0QqC9Yf0khRgRERGvUYjphMbJ7k6oOUlERMRrFGI6obE5STUxIiIi3qMQ0wmNIUZrJ4mIiHiPQkwnuNdO0jwxIiIiXqMQ0wnumpg61cSIiIh4i0JMJ6gmRkRExPsUYjpB88SIiIh4n0JMJwTZ1ZwkIiLibQoxnRDg19icpBAjIiLiLZ0KMcuWLSMpKQl/f3/S0tLYuHFjh6578803sVgsXHfddc32G4bBwoULiYuLIyAggPT0dPbt29eZovUKd02MJrsTERHxGo9DzIoVK5g/fz6LFi1iy5YtjB07lmnTplFYWHjK6w4dOsSCBQu4+OKLWxx77LHHePrpp1m+fDkbNmwgKCiIadOmUV1d7WnxeoV7Fes6J4ZheLk0IiIiZyaPQ8yTTz7JvHnzmDt3LmPGjGH58uUEBgby4osvtnmN0+nk5ptvZvHixQwdOrTZMcMwWLJkCb/97W+ZMWMGKSkpvPrqq+Tm5vLee+95/IV6Q+Mq1oYB1XUuL5dGRETkzORRiKmtrWXz5s2kp6c33cBqJT09nfXr17d53YMPPkh0dDS33HJLi2NZWVnk5+c3u2dYWBhpaWlt3rOmpgaHw9Fs600Bfj7u95VqUhIREfEKj0JMcXExTqeTmJiYZvtjYmLIz89v9Zq1a9fywgsv8Pzzz7d6vPE6T+6ZkZFBWFiYe0tMTPTka3SZ1WpxBxktPSAiIuIdPTo6qby8nB//+Mc8//zzREZGdtt977vvPsrKytzbkSNHuu3eHdW0CKRqYkRERLzB15OTIyMj8fHxoaCgoNn+goICYmNjW5x/4MABDh06xLXXXuve53KZfUh8fX3Zu3ev+7qCggLi4uKa3TM1NbXVctjtdux2uydF73aBdh9KKjXhnYiIiLd4VBNjs9kYN24cmZmZ7n0ul4vMzEwmTZrU4vxRo0axY8cOtm3b5t6++93vcvnll7Nt2zYSExNJTk4mNja22T0dDgcbNmxo9Z59RWDDXDFVmitGRETEKzyqiQGYP38+s2fPZvz48UycOJElS5ZQWVnJ3LlzAZg1axYJCQlkZGTg7+/POeec0+z68PBwgGb7f/WrX/Hwww8zYsQIkpOTuf/++4mPj28xn0xfEmhvXHpAzUkiIiLe4HGImTlzJkVFRSxcuJD8/HxSU1NZuXKlu2NudnY2VqtnXW3uvvtuKisrufXWWyktLeWiiy5i5cqV+Pv7e1q8XqP1k0RERLzLYpwGs7U5HA7CwsIoKysjNDS0Vz5z3qtf8vGuAn5//bn8MG1wr3ymiIjI6aSrf7+1dlInNdXEqDlJRETEGxRiOimwYdZeNSeJiIh4h0JMJ2meGBEREe9SiOmkIJtm7BUREfEmhZhOCmhoTqrUPDEiIiJeoRDTSUEN88ScqFNzkoiIiDcoxHRS4wKQqokRERHxDoWYTgqym81J6hMjIiLiHQoxnRSg0UkiIiJepRDTSUE21cSIiIh4k0JMJ2meGBEREe9SiOkkLQApIiLiXQoxnXTysgOnwRqaIiIi/Y5CTCcFNswT43QZ1DpdXi6NiIjImUchppMCG+aJAajSXDEiIiK9TiGmk3x9rNh8zcdXVacQIyIi0tsUYrrA3bm3RiOUREREeptCTBcEndS5V0RERHqXQkwXaNZeERER71GI6YKghhCjWXtFRER6n0JMFzTVxCjEiIiI9DaFmC5oWj9JzUkiIiK9TSGmC9w1MZonRkREpNcpxHSBuyZG88SIiIj0Ol9vF6BPqyiE7W+Bqx4u+lWLw001MWpOEhER6W2qiTmVqmPw0W9g7ZOtHg6yayVrERERb1GIOZXQOPO1ugxqK1scblrJWjUxIiIivU0h5lTsoeAXZL535LU47F52QDUxIiIivU4h5lQslqbamPLcFocVYkRERLxHIaY9IQ0hptWaGDUniYiIeItCTHtCE8xX1cSIiIj0KQox7QntSE2MQoyIiEhvU4hpT0i8+eo42uKQuyZG88SIiIj0OoWY9rg79rasiXHPE6MZe0VERHqdQkx73DUxLUNMQGNzktZOEhER6XWdCjHLli0jKSkJf39/0tLS2LhxY5vn/v3vf2f8+PGEh4cTFBREamoqr732WrNz5syZg8ViabZNnz69M0Xrfo01MRUF4GoeVoIampNqnS7qnK7eLpmIiMgZzeO1k1asWMH8+fNZvnw5aWlpLFmyhGnTprF3716io6NbnD9gwAB+85vfMGrUKGw2G//85z+ZO3cu0dHRTJs2zX3e9OnTeemll9w/2+32Tn6lbhYcAxYfMJzmWkqNoYamtZPA7NwbFqCKLRERkd7i8V/dJ598knnz5jF37lzGjBnD8uXLCQwM5MUXX2z1/Msuu4zrr7+e0aNHM2zYMO666y5SUlJYu3Zts/PsdjuxsbHuLSIionPfqLtZfcwgA+BoPsza5mPFx2oB4IRGKImIiPQqj0JMbW0tmzdvJj09vekGVivp6emsX7++3esNwyAzM5O9e/dyySWXNDu2evVqoqOjGTlyJLfddhslJSVt3qempgaHw9Fs61FtzNprsVjcI5QqNeGdiIhIr/IoxBQXF+N0OomJiWm2PyYmhvz8/DavKysrIzg4GJvNxjXXXMMzzzzD1KlT3cenT5/Oq6++SmZmJo8++ihr1qzhqquuwulsvXYjIyODsLAw95aYmOjJ1/DcKWftNUOMamJERER6l8d9YjojJCSEbdu2UVFRQWZmJvPnz2fo0KFcdtllANx0003uc88991xSUlIYNmwYq1evZsqUKS3ud9999zF//nz3zw6Ho2eDTGjDCKVWZu0NsvkCNVRqrhgREZFe5VGIiYyMxMfHh4KCgmb7CwoKiI2NbfM6q9XK8OHDAUhNTWX37t1kZGS4Q8y3DR06lMjISPbv399qiLHb7b3b8Tf0VMOsNVeMiIiIN3jUnGSz2Rg3bhyZmZnufS6Xi8zMTCZNmtTh+7hcLmpqato8npOTQ0lJCXFxcW2e06tC2quJ0VwxIiIivc3j5qT58+cze/Zsxo8fz8SJE1myZAmVlZXMnTsXgFmzZpGQkEBGRgZg9l8ZP348w4YNo6amhg8//JDXXnuNZ599FoCKigoWL17MDTfcQGxsLAcOHODuu+9m+PDhzYZge5V7/aSWIcZdE6OOvSIiIr3K4xAzc+ZMioqKWLhwIfn5+aSmprJy5Up3Z9/s7Gys1qYKnsrKSm6//XZycnIICAhg1KhRvP7668ycORMAHx8ftm/fziuvvEJpaSnx8fFceeWVPPTQQ31nrpiTZ+01DLBY3IfcSw+oY6+IiEivshiGYXi7EF3lcDgICwujrKyM0NDQ7v+A2kr4fUOQuTcb/MPch3791lf8bUsO90wfxW2XDev+zxYRETlNdfXvt6aY7QhbUFNw+Vbn3qaaGDUniYiI9CaFmI5qo3NvU58YNSeJiIj0JoWYjmqjc697dJJqYkRERHqVQkxHhbQ+V0ygamJERES8QiGmo9pYPymwoSamUvPEiIiI9CqFmI5qY/0k99pJdWpOEhER6U0KMR0VmmC+tqiJUXOSiIiINyjEdFQbHXsDteyAiIiIVyjEdFRjx97KIqivde8ObJwnRs1JIiIivUohpqMCB4LVz3xfkd+0u7E5STUxIiIivUohpqOs1lY79zbNE6MQIyIi0psUYjwR2nLW3gD36CQnLle/X4ZKRESk31CI8URo2zUxYAYZERER6R0KMZ5wz9p71L3L38+KxWK+r9TSAyIiIr1GIcYT7ll7m2piLBYLgX4NTUrqFyMiItJrFGI80casvQFaekBERKTXKcR4oo1Ze4PsWnpARESktynEeOLkjr1G00ikgIbmJNXEiIiI9B6FGE80Nic5a6DqmHt3kN1sTiqvVk2MiIhIb1GI8YSv3Zy5F5o1KQ2NDAJgd57DG6USERE5IynEeMo9zLqpc+95gyMA2HrkuDdKJCIickZSiPFUK7P2njc4HICvjpTh1Ky9IiIivUIhxlOtzNp7VkwIgTYfKmrq2V9Y4aWCiYiInFkUYjzVyqy9PlYLYweFA7A1W01KIiIivUEhxlOtzNoLTU1KW7NLe7c8IiIiZyiFGE+10rEX1LlXRESktynEeMpdE9N81t7UxHAA9hVW4Kiu6+VCiYiInHkUYjzVODrpxHGoO+HeHRViZ1BEAIYB24+UealwIiIiZw6FGE/5h4NvgPm+Rb+YhiYlde4VERHpcQoxnrJYThpm3bxJ6byGJqVtR0p7t0wiIiJnIIWYzmizc284AFuPlGIYmvRORESkJynEdEYbnXvHxIdi87FyrLKW7GNVXiiYiIjImUMhpjNCW6+Jsfv6cHZCKKD5YkRERHqaQkxnhLRcP6nReYnq3CsiItIbFGI6o42OvdC8X4yIiIj0nE6FmGXLlpGUlIS/vz9paWls3LixzXP//ve/M378eMLDwwkKCiI1NZXXXnut2TmGYbBw4ULi4uIICAggPT2dffv2daZovaONjr3QFGJ25TqornP2YqFERETOLB6HmBUrVjB//nwWLVrEli1bGDt2LNOmTaOwsLDV8wcMGMBvfvMb1q9fz/bt25k7dy5z585l1apV7nMee+wxnn76aZYvX86GDRsICgpi2rRpVFdXd/6b9aTGmpiKfHC5mh1KCA8gKsROvcvg66Oa9E5ERKSneBxinnzySebNm8fcuXMZM2YMy5cvJzAwkBdffLHV8y+77DKuv/56Ro8ezbBhw7jrrrtISUlh7dq1gFkLs2TJEn77298yY8YMUlJSePXVV8nNzeW9997r0pfrMcExYLGCqx4qi5odslgs7vli1LlXRESk53gUYmpra9m8eTPp6elNN7BaSU9PZ/369e1ebxgGmZmZ7N27l0suuQSArKws8vPzm90zLCyMtLS0Nu9ZU1ODw+FotvUqHz8Iijbft9a5V4tBioiI9DiPQkxxcTFOp5OYmJhm+2NiYsjPz2/zurKyMoKDg7HZbFxzzTU888wzTJ06FcB9nSf3zMjIICwszL0lJiZ68jW6h7tzb9v9YlQTIyIi0nN6ZXRSSEgI27ZtY9OmTfzud79j/vz5rF69utP3u++++ygrK3NvR44c6b7CdpS7c+/RFodSBoVhtUBeWTV5ZSdaHBcREZGu8/Xk5MjISHx8fCgoKGi2v6CggNjY2Davs1qtDB8+HIDU1FR2795NRkYGl112mfu6goIC4uLimt0zNTW11fvZ7XbsdrsnRe9+7ll7W9bEBNp8GRUbyq48B9uyS4k7N6CXCyciInL686gmxmazMW7cODIzM937XC4XmZmZTJo0qcP3cblc1NTUAJCcnExsbGyzezocDjZs2ODRPXtdSNvNSaD5YkRERHqaRzUxAPPnz2f27NmMHz+eiRMnsmTJEiorK5k7dy4As2bNIiEhgYyMDMDsvzJ+/HiGDRtGTU0NH374Ia+99hrPPvssYI7m+dWvfsXDDz/MiBEjSE5O5v777yc+Pp7rrruu+75pdwtNMF9b6dgLZufev2zI1sy9IiIiPcTjEDNz5kyKiopYuHAh+fn5pKamsnLlSnfH3OzsbKzWpgqeyspKbr/9dnJycggICGDUqFG8/vrrzJw5033O3XffTWVlJbfeeiulpaVcdNFFrFy5En9//274ij3kFB17oakmZntOGXVOF34+mhxZRESkO1kMwzC8XYiucjgchIWFUVZWRmhoaO98aNE3sGwC2ELg/3JaHHa5DM576GPKTtTxwR0Xce6gsN4pl4iISD/R1b/fqh7orMaamNpyqClvcdhqtZDaOOmd5osRERHpdgoxnWUPMWthoP3OvZovRkREpNspxHRFaMNcMW107nXXxKhzr4iISLdTiOmKdjr3NoaYQyVVHKus7aVCiYiInBkUYrriFLP2AoQH2hgaFQTANvWLERER6VYKMV1xill7G52XaC4GuU39YkRERLqVQkxXtDNrL2jmXhERkZ6iENMV7czaC00hZlt2KS5Xv5+SR0REpM9QiOmKdjr2AoyMCSHAz4fymnoOFFX0UsFEREROfwoxXdHYsbeiAJx1rZ7i62MlpWG2Xs0XIyIi0n0UYroiKAqsvoBhBpk2nDfY7NyrmXtFRES6j0JMV1itEBxrvu9I517VxIiIiHQbhZiuamfWXoDzGia921tQTkVNfS8USkRE5PSnENNVHejcGx3qT0J4AIYB2zXUWkREpFsoxHRVSPs1MaD5YkRERLqbQkxXuWti2gsxZufev23O0TpKIiIi3UAhpqvc6ye13ZwEcO3YOGJC7RwsruRHf95AWVXrQ7JFRESkYxRiusq9ftKpa2KiQ/z5y08vIDLYxq48B7Ne2kh5tYKMiIhIZynEdFXoSTUxxqmXFRgeHczrP00jPNCPr46U8pOXN1FVq9FKIiIinaEQ01WNi0DWn4Dq0nZPHxUbyms/SSPE35dNh44z79Uvqa5z9mwZRURETkMKMV3lFwABZqfd9vrFNDp3UBgvz51IoM2Hz/eXcNvrm6mtd/VgIUVERE4/CjHdobFzb+GuDl8ybkgEL86ZgL+flU/3FnHnX7dQ51SQERER6SiFmO6QdJH5+uECKDnQ4csuGDqQP/14PDYfK6t2FjD/ra9wuk7dr0ZERERMCjHdIf0BiD8fThyHN2aarx10yVlR/PHm8/G1Wvjgq1zu+dt2XAoyIiIi7VKI6Q62QPjBXyE0AUr2wdtzwNnx4dPpY2J4+gfnYbXAO5tz+M17O9RHRkREpB0KMd0lJBZ+8Cb4BcHB1fDh/9fukOuTXX1uHE/emIrFAn/deITrln3O7jxHz5VXRESkn1OI6U5xKXDD84AFNr8EG5Z7dPl15yXw7M3jiAj0Y1eeg+8uXcvS/+yjXh1+RUREWlCI6W6jroGpD5rvV/0ffPORR5dPPyeWj/73UqaOiaHOafDER99ww7Pr2F9Y3gOFFRER6b8UYnrChXfCeT8GwwXv/AQKdnp0eVSInT/9eBxP3jiWEH9fvsop4+qn1/L8Zwc1eklERKSBQkxPsFjgmidhyEVQWw5v3AQVhR7ewsL3zh/Ex/97KZeeFUVtvYvffbibm/60nkPFlT1UcBERkf5DIaan+Npg5mswYCiUZcObN0Ndtce3iQ3z5+W5E3jke+cSZPNh06HjXPXUf3ll3SH1lRERkTOaxTA8GELTRzkcDsLCwigrKyM0NNTbxWmueB/8eQpUl8G5/wPfe96sqemEI8equPud7aw/WALAwCAbV58bx3dT4xk3OAKrtXP3FRER8Yau/v1WiOkNB1fD6zeAqx4m3gpX/s6sqekEl8vg9Q2HeeqTfZRU1rr3x4f5852x8Xx3bDxnx4di6WRQEhER6S0KMfSDEAOw+WX44C7zfdxYuOEFiBzR6dvVO118fqCED77KZdXX+ZTX1LuPDY0Mcgea4dHBXSy4iIhIz1CIoZ+EGIDd/4R/3GEuS+AXCNMz4PzZnW5ealRd52T13iI++CqXT3YXUHPSbL8Tkwfwf1ePJjUxvIuFFxER6V5d/fvdqY69y5YtIykpCX9/f9LS0ti4cWOb5z7//PNcfPHFREREEBERQXp6eovz58yZg8ViabZNnz69M0Xr20Z/B25bD8mXQl2VWTOz4kdQdaxLt/X382H6ObEsu/l8Nt8/lSUzU7liVDS+Vgsbs45x3bLPuevNrRwtPdFNX0RERMT7PA4xK1asYP78+SxatIgtW7YwduxYpk2bRmFh60OIV69ezQ9+8AM+/fRT1q9fT2JiIldeeSVHjx5tdt706dPJy8tzb3/961879436utA4+PF75oR4Vj/Y8094djIcXNMttw+2+3LdeQm8OGcC/73ncm44fxAA72/L5YonVvP4qj1UnNT0JCIi0l953JyUlpbGhAkTWLp0KQAul4vExETuvPNO7r333navdzqdREREsHTpUmbNmgWYNTGlpaW89957nn8D+lFz0rflboO/3QIl+wELTP4lXP7bTnf6bcuOnDIe/tcuNmSZNT6RwTbmTx3JjeMH4evTdo51uQwOH6tix9EysooqmZg8gAuGDlCnYRER6RZd/fvt68nJtbW1bN68mfvuu8+9z2q1kp6ezvr16zt0j6qqKurq6hgwYECz/atXryY6OpqIiAiuuOIKHn74YQYOHNjqPWpqaqipqXH/7HD004US41PhZ5/Byvtgyyvw+VNmjcwNL0Dk8G77mHMHhfHmrRfw8a4CMv69h6ziSv7v3R28su4Qv7lmNJecFYXTZZBVXMGOo2V8fdTBjqNl7Mp1tKi1mZg0gF9OGcHk4QMVZkRExKs8qonJzc0lISGBdevWMWnSJPf+u+++mzVr1rBhw4Z273H77bezatUqdu7cib+/PwBvvvkmgYGBJCcnc+DAAf7v//6P4OBg1q9fj4+PT4t7PPDAAyxevLjF/n5XE3Oy3R/AP+40O/1a/SDlRnP5gujR3foxtfUuXv/iME9l7qPsRB0Aw6ODyS09QVWts8X5dl8ro+NCiQ/355NdhdQ2TLA3bkgEv5wygktGRCrMiIhIp/Tq6KSuhphHHnmExx57jNWrV5OSktLmeQcPHmTYsGF88sknTJkypcXx1mpiEhMT+3eIAXDkwvt3wIHMpn0jpsHku2DIhV0exXSy0qpanvnPfl5df4g6p/lPIMDPh7PjQzknIaxhC2V4VLC7ySm/rJrnPjvAGxuy3SOgxiaGc9eU4Vw+MlphRkREPNKrIaa2tpbAwEDeeecdrrvuOvf+2bNnU1payvvvv9/mtU888QQPP/wwn3zyCePHj2/3s6Kionj44Yf52c9+1u65/bZPTFuObIJ1T5lDsmn49SSMM8PMqO+AtWXtVKc/6lgVXx8tY0RMMMmRwfh0YNbfwvJq/rTmIK9vOEx1nRlmzkkI5ZdXjGDqmBiFGRER6ZBeHWJts9kYN24cmZlNNQUul4vMzMxmNTPf9thjj/HQQw+xcuXKDgWYnJwcSkpKiIuL86R4p4/ECTDzdbjjSxg3F3zscHQzvDULlo6HTS9AXfcMl04cEMhV58YxPDqkQwEGIDrEn99+Zwxr77mCn106lECbD18fdXDra5u5+um1fLQzn9Ng+iEREenjPB6dtGLFCmbPns1zzz3HxIkTWbJkCW+99RZ79uwhJiaGWbNmkZCQQEZGBgCPPvooCxcu5I033mDy5Mnu+wQHBxMcHExFRQWLFy/mhhtuIDY2lgMHDnD33XdTXl7Ojh07sNvt7ZbptKuJ+baKItj4J9j0vNlnBiBgAAyeBDFnQ+w5EHMORCSDtffX9DxWWcuf/3uQV9YdorKhX805CaHMn3qWmplERKRNXpmxd+nSpTz++OPk5+eTmprK008/TVpaGgCXXXYZSUlJvPzyywAkJSVx+PDhFvdYtGgRDzzwACdOnOC6665j69atlJaWEh8fz5VXXslDDz1ETExMh8pz2oeYRrWVsPV1WL8USrNbHrcFQ/SYhlBzNsScay5x4OffK8U7XlnLn9ce5KXPD7k7CY9NDOd/00dw6VlRHQozTpfBrlwHW7KPExls55KzIgnx9+vpoouIiBdo2QHOoBDTyFkPRzZA/g4o2AH5X0PhbnDWtDzXHgpjvgspM2HIRb1SU1NSUcOf/nuQV9cd5kSdGWbOHxzO/KkjWwzNrne62JXnYMPBY3xxsISNh45RXt00rNvmY2XSsIFceXYMU0fHEB3aO4FMRER6nkIMZ2CIaY2z3pw0r+DrhnDzNeR9BZVFTeeEJsC53zcDTczZPV6kovIanltzgNe+OOwezTQxaQBzJydx5HgVXxw8xqasY80WrwQIsfty/pAIjhyr4mBxZbNj5w0OZ+qYGK4cE6vFLUVE+jmFGBRi2uRywZEvYPsK2PkuVJc1HYs+25yL5tz/gbCEHi1GoaOaP64+wBsbs6k9aXHKRiF234bZgAdywdCBjIkPdXcy3l9YwUe78vloZwHbjpQ2u25oVBBXnxPHvIuHEhaoJicRkf5GIQaFmA6pr4FvVpmBZt9H4KxtOGCBxIkQeRZEDDE7B4cPgYgkCIrs1rlp8suq+ePq/az5pogR0cHu0DI6LrRDI6MKHNV8sruAj3YWsP5AiXvivYFBNu65ahTfP38Q1g6OsDpZbukJnv/vQQwDbr9smJqsRER6iUIMCjEeqzoGu96H7W9B9rq2z/MLMoNNY6iJT4XENPO9l0cclVfX8eneIp7O3Mf+wgrA7Hfz4IxzOCchrEP3KHRUs+zT/fx14xF3IArw82HeJUO59ZKhBNs9WpVDREQ8pBCDQkyXHD8Mh9dB6WHz/fFD5ntHLu6J9r4tOAYGXwCJF8DgNIhNAR/vNOfUOV289HkWT32yj8paJ1YL/OiCIfx66sg2m5iKK2pYvrp5X5205AHUOV1syS4FzEUy70o/i5smJOJ3ikUyRUSk8xRiUIjpEfU1UHoESg+ZwabkIORsgtyt4Kprfq5foDmjcGOwGTQOAiJ6tbj5ZdX87sPdfPBVLtB6E9Pxylqe+8ycz6Zx1NS4IRH8eupZTBpmLja6amc+j67cS1ZDh+KhUUHcO32UZiIWEekBCjEoxPSquhNmkMn+wtyObIDq0pbnRZ4FgyY0bdGju3W5hLasO1DMwvd3Nmtiumf6KNbuL+bFtVnuyfjGDgpj/pUjW13Ass7p4q8bs1nyyT6OVZp9hyYmDeC+q0dx3uDeDWciIqczhRgUYrzK5YLibyB7vRlojmyEYwdanmcLhvjzzE7EgyZC8iVgC+yRItXWu3h5XRZLPtnXYmXuMXHmTMJTRrc/k3B5dR3L1xzgz//Ncjc7XXNuHPdeNYrEAT1TdhGRM4lCDAoxfU5lCRz90gw0OZvMdZ9qK5qf4xsAI9Jh9HfhrGng37HOuJ7IKzvB7/61m39uz2NkTAj/O3UEV46J9XgEU17ZCZ786Bve2ZKDYYDd18ptlw3j55cOw9+v52uXREROVwoxKMT0eS4nFO1pCDVfQtZnUHbSsglWPxh6GYy+FkZdYw7t7kbFFTUMCLR1avj1yXbnOXjon7tYd6AEgEERAfz2mjFMO1v9ZUREOkMhBoWYfscwzNmEd39gbsV7m45ZrDBkshlohl0BA4Z5ZVHLthiGwYc78vndv3aRW1YNwMUjIll07dm9PoOw02XwVU4pn+8rJjrUzo3jExWmRKRfUYhBIabfK9oLu/9hBpq8r5ofs4dB/FiIP9/sU5NwPoQlen2emqraev746QH+9NlBap0ufK0WfnJRMr+cMuKU88vUOV3kHD/BoeJKKmvrSRoYRFJkUIfnpClwVLPmmyLWfFPE2n3FlJ1oGil2y0XJ/Paa0QoyItJvKMSgEHNaOX4Y9vwT9vzL7EtTX93ynMDIpkATl2qOfAof4pUam0PFlTz0z11k7ikEIDrEzn1Xj2L8kAEcKqkkq9jcDjW85hw/Qb2r5f/kYkLtJEcGMTQqmKGRQQyNCmJoZDDRoXa2ZpfyWUNw2ZNf3uy6UH9fxiaG8999xQDMHJ/I7793bodmQBYR8TaFGBRiTlvOeijaDUe3mMO6c7dAwU5w1bc81y/QHNYdPRqiRjW9hiX2Srj5z54CFn+wi8MlVe2e6+9nJWlgEIE2Hw6XVFFSWdvuNY0sFkgZFM6lIyK5dGQUYweF4+tj5e0vj3DP37bjMuCalDj+cGMqNt++0wwnItIahRgUYs4oddVmkMndYoab/B3mEG9nTevn+wVB1EgIH2yu4h0aby542fg+OBZ8umd5geo6Jy+szeKPn+6nzmkweGAgSQODSI4MJCkyiOSGLSbEv1kn47KqOg4WV5BVXMnBIrPG5mBxJVnFFVTXuYgKsXPJiCguHRnFRcMjGRBka/XzP9yRx11vbqXOaXD5yCie/dE4jZ4SkT5NIQaFmDOes96cVbhoNxQ2bEV7oHhfy9mFv81iNZdRCI2HkDgIiTWDTchJW3AsBA7scI1OvdOFxWLpcpOOy2VwvKqWAUG2DvdzWb23kJ+/vpnqOhdpyQP48+zxhPh375IQxytrqXO5iA7RQpki0jUKMSjESBucdXDsoNlx2HG0Yctt2I6CI6/9kNPI6tsUduJSGybtG2+u+t3HOtJuzDrGLS9vorymnpRBYbwydyIRbdTenEpVbT37CirYW1DO3vxyvikoZ09+OUXlZq3XqNgQrhgVzZTR0aQmRqgfjoh4TCEGhRjpJJcLqorNQFN2FMrzoKLAfC0vgIp8KM+HymLaXAwzMNJcViGxYXmF+PPB3rtDrVvz9dEyfvzCBo5X1XFWTDCv35JGdGjrNSeGYZBz/AQ7c8vYletgT345ewvKyT5WRVv/dbBa4OT+yQOCbFw2Moopo2K4+KxIQru59kdETk8KMSjESA9z1kFFoRlqjmWZo6ZyNpnDwZ3f6pRrsUL02ebIqfhUs9Ym5mzwtfd6sfcVlPOjFzZQ4Khh8IBA/vLTNOLC/DlQVMnO3DJ25jrcwcVR3UpnaSAy2M7I2GBGxoQyMjaYs2JCOCsmhDqnizXfFPHJ7kLW7C1sdr2v1cLE5AFcMSqa76bGq9lJRNqkEINCjHhJXbXZsTinYXmFI5vAkdPyPKsfxIwxA00vB5sjx6q4+c8byD5WRYjdl1qny70O1MlsPlbOig3m7LgwRsWFMDI2hJExIQwMbr+MdU4Xmw8f5z97CsncXcCBokr3MT8fC1efG8ecC5O0eKaItKAQg0KM9CGOXDPQ5G6F3G2Qtw1OHG95ntXPHBIePhjCE82h4GGDzJ/DEiEoqtuGhhc4qvnRnzewr2Fl7yCbD2fHhzEmPpSz40M5Oz6M4dHB3TYk+1BxJZl7Cvnn9ly2Zpe6948dFMbsC5O4JiUOu69GTYmIQgygECN9mGFAabYZZnK3meGmrWBzMh+7ORS8MdyEJjQMDR/UNETcv+P/1sur69iYdYyhUcEMGRDY5XWkOmpHThkvrzvEB1/lUus0a4Aig238YOJgbk4bQmxY55qaDMPgeFUdheXVFDhqKHRUU1JZS1yYP+cPjmBQRIBmLhbpBxRiUIiRfqYx2BTthbIjDVsOlDa8L88Do2WTTwv2sOZz3oTEQWhc01DxkDiz43EfWHuquKKGNzdm8/oX2eQ7zFmYfa0Wpp8Ty0XDI6l3GdQ7XdS7DOqc5vs6p4u6hv0n6pwUOmooLK+hqLyGwvJq6pxt/6crOsTO+YMjGDckgvOHhHN2fJjmzBHpgxRiUIiR04yzzmyWKjtiBhtHjjl6qnEUVVkO1JR17F5W36Z5b4JjwB4CtqBWtuCm97EpEDigR75andPFRzsLeGXdITYeOtbl+w0IshEdYicqxM7AIBtZxZXszHW0WNrB5mPl7IRQd7CZkDSAqJDe72wtIs0pxKAQI2egmvKGYJPTNDy8PM8cEu7IbRgaXkSbQ8NPxeoLw6fC2Jlw1nTwC+j24gPszC3jrxuzySutxtfHgq+PFT9rw6uPBV+rFV8fC34+Vvx9rUSF2IkK8Scm1E50qD9RwfZW+/GcqHWy42gZW7KPs/nwcbZmH6e4ouXSDsmRQUxIMgPNhKQBDBkYqCYokV6mEINCjEirGoeGl+dDea75vrayYauAuqrmP9dWQlWJOUFgI3sojPkupNwEQyb3iaYpTxmGQfaxKneo+fLQcfYWlLeYAyc6xN4QaCKYkDyAkTEh+Pr0v+8r0p8oxKAQI9KtCnfD9rdgx9tmk1aj0AQ4938gZaY5ZLwfK6uqY3P2MTZmHWfToWNszylt0cfG38/K6LhQUhLCOCchjJRB4QyLClKwEelGCjEoxIj0CJcLstfB9hWw8/3m/XAGDjdXCR84HAYOa3gdbg4N74dNMtV1Tr46UsqmQ8fYeOg4Ww8fp7ym5QSA/n5Wzo4P49wEc7tw+EDiwnqmuU3kTKAQg0KMSI+rq4Z9q+CrFbDvo7bXnLKFNIWaAclm/xqXE1z1YDgb3jsb3teb7wcOh7E/gOCo3v1Op+ByGRwqqWTH0TK255Sx42gZO4+WUVnrbHaer9XCd1Pj+fmlwzgrJsRLpRXpvxRiUIgR6VVVx8ylF0oOwLEDULLf3EqP0KmOxAA+NhgzA8bfAoMv6JO1OS6XwcHiSnYcLWVHjoPN2cf56kip+3j66Gh+fukwxif1zMgukdORQgwKMSJ9Ql01HD90UqjJNue7sfqC1cd8tVib/wxmzc7RzU33iR4D439i9r3xYEI/b/jqSCnL1xxg5c58d0fhCUkR3HbZMC4fGa3RTiLtUIhBIUak38vdCptegB3vQP0Jc59fEKTcCBNugdhzW15jGFBf0zS6qr7aXLahq0PCS7MhbzsMubDD8+UcKKrg+c8O8rctOe4OwqNiQ/jZpUP5Tko8ft3QGdjlMqhzubD5WBWO5LShEINCjMhp40QpfPUmfPkCFH/TtD96jFlzU1t50tDwipYzG/v6Q/KlcNaVMGKauS5VewwDivbA7g/MLX+7ud8eCpN/CRfcbk4C2AEFjmpeXJvF618cdvefiQy2MzQyiOhQOzGh/kSHNL1Gh5rz3gTbfampd5FbeoKjpSfM1+MnOFpa7d6XV3aCOqeBr9VCoM2HYLsvgXZfguy+BNl83K8h/n4kRQYxIjqYETHBxIb69+nQU1ZVx558B3sLyskrq+aCoQOZPGygRoGdIRRiUIgROe0YBhxaa4aZ3R+YnYBPxdffXFSztrz5/ugxcNY0M9AMmgA+DU1YLpfZhLXnA9j9T7NvTyOL1ZzluDzX/Dk4Bi69B86fBT5+HSp+WVUdr284zEufZ7U60d632X2tra4u3h2C7b4Mjw5mRHSw+RoTzIjoEGLD/Lulhqij6p0usoor2Z1fzp48B3saXnPLqlucGxls4zsp8cxIjSc1MbxPhzDpGoUYFGJETmvlBZCz0QwqjUsj+H1r2QSrjxl8CnfBN6vMfjZHNjSvqfEPh+HpZj+bvf82Zzhu5GODoZfD6O/AyKshYAB8/Tf4z0NQetg8Z8AwuOK3MOa6Dk/6V13nZHtOGQWOagrLzYUqG98XOKopdNQ0G8odZPMhISKA+HBzS2jY4sMDSIgIINjuS1VtPZU1Tqpq66moqaeqxkllw77KmnpKT9RysKiSfYUVHCqubLEEw8n8/awE2/0I8fcl2N6w+fsSYvclxN+XyGA7l4+K5uz40E4FibKqOj78Oo/3tx1lS3YptW0EtYTwAEbFhhAeaOM/ewo4XtU0+m3IwEBmjI3nu6kJDI8O9rgM0rd5JcQsW7aMxx9/nPz8fMaOHcszzzzDxIkTWz33+eef59VXX+Xrr78GYNy4cfz+979vdr5hGCxatIjnn3+e0tJSJk+ezLPPPsuIESM6VB6FGBFpoeoY7M80h4bv/6TlyuG2ELPZadR3YMRUc12pb6uvhc0vwZrHoKrY3BeXCukPwLDLW55fd6Khc/MBc+bjYwfNJSKSLzZrg0LjWhaztp7i8lrCAvwIDfDt1lqH2noXh0vMQLOvoIL9RRXsKyjnYFGle1XxjkgID2Da2bFMPyeWcUMi8DnFKujVdU4+3VPIe9uO8umeomafE2jzYVRsCCNjQxkdF8Ko2FBGxoYQFtBUw1XndLF2XzHvbTvKRzsLOFHXNKz9nIRQZoxN4Dtj4zQ/z2mi10PMihUrmDVrFsuXLyctLY0lS5bw9ttvs3fvXqKjo1ucf/PNNzN58mQuvPBC/P39efTRR3n33XfZuXMnCQkJADz66KNkZGTwyiuvkJyczP3338+OHTvYtWsX/v7+7ZZJIUZETslZD0e/NGtpaivMtaGGXgq+HVwEsqYc1i+Ddc+Y1wMMvcysvTme1RBassxFOk81zDwuFUZeZTZxxaV6bSi502VQUV1PeU0d5dVmjY75cz3l1XVUNOzbV1DBmm+KmgWJyGAbU8fEMO3sWC4cFonN14rLZbAh6xjvbT3Kh1/nUV7dVLs0KjaEGakJTDs7hqSBQVhPEYC+raq2no93FfD+tlw++6aoWa3SeYPDueqcWK46J47EAYHd82Ck1/V6iElLS2PChAksXboUAJfLRWJiInfeeSf33ntvu9c7nU4iIiJYunQps2bNwjAM4uPj+fWvf82CBQsAKCsrIyYmhpdffpmbbrqp3XsqxIhIr6gogs8ehy9fbHvCP3soDBhqTvo3YChYfMyaoKObaRZwQuJgxJXmIptDLwNb3/xDfKLWyWf7ili1M59PdhXgOCmghPj7MmnoQHYcLSPvpL4tcWH+fDc1nutSExgd1z3/TT5WWcu/duTxj21H+fLw8WZrX52TEMpV58Rx1TmxDI06fZucXC6D4soackurKa2q5fwhEYT6d6yfVl/VqyGmtraWwMBA3nnnHa677jr3/tmzZ1NaWsr777/f7j3Ky8uJjo7m7bff5jvf+Q4HDx5k2LBhbN26ldTUVPd5l156KampqTz11FPt3lMhRkR61bEsWL/UbLIaOMzsL9MYWgIHtl7DUlFo9tXZ+2848CnUVTYd8/U3++ucc4MZavpooKlzuvjiYAmrduazamcBReU17mMh/r5cc24cM1ITSEse4FGNi6cKHdWs2pnPhzvy2ZBVwsndfkbGhDD9nFimjolheHQw/n4+PVaOnlBZU8+GrBKOllaTV3qCvLJq9+i0/LLqZmt8RYXYeWjG2Uw/p2UzZX/RqyEmNzeXhIQE1q1bx6RJk9z77777btasWcOGDRvavcftt9/OqlWr2LlzJ/7+/qxbt47JkyeTm5tLXFzTL+LGG2/EYrGwYsWKFveoqamhpqbpfzwOh4PExESFGBHpH+pr4NB/zeatvSuhLLvpmC3Y7Fx87vfN5ipfm/fKeQoul8HWI6V8cbCEYVFBXDYy2iuBoaSiho93FfDh1/ms21/coiNzfJg/SZFBJDdsSQODSI4KIjEiEJuv1f1djlfVUlJZS3FFDcUVtZRU1FBSUUtJZQ2BNl8uHDaQtKEDCbb79th3+aagnJ+8vImc4yfaPMdqgZhQf1yGQYHD/Ds47ewYHpxxDjGh7Xe/6Gu6GmJ67rfRikceeYQ333yT1atXd6ivS1syMjJYvHhxN5ZMRKQX+drNmpfh6XDVY1DwtTka6uu/mZPt7XjL3AIizOUYzvm+Ofmete/UKlitFsYNiWDckAivlmNgsJ2bJg7mpomDKauq4+PdBaz8Oo+NWcdwVNeTW1ZNblk16w6UNLvOx2ohNtSfmnoXxyprOMUgLgBeWJuFj9VCamI4k4cNZPLwSM4bHOEOQl31331F3P76Fspr6okOsZMyKJz4cH/iwwOIC/N3j1iLCbHj62Olus7Jsk/38+zqA6zaWcC6/SXcd/VobpqQ2KO1YH1NrzUnPfHEEzz88MN88sknjB8/3r2/M81JqokRkdOSYUDOJnPm4p3vQmVh07GQOEi+xJyR2MfWsPl967XhvV+geZ5fUMNrw8+2wJPeB/fJNaq6i2EYHK+qI6u4kqziSg4VV5JVUklWUSWHSiqp+tZingDhgX4MDLIRGWwnMtjOwGAbA4JsFDhqWHegmMMlVc3OD/DzYWLyACYPH8hFw6MYHRfSqdFlb2zI5v73v8bpMpiYPIDnfjSOiKCO1cDtyXdwz992uNfxmpg8gIzvncuwftI3yCsdeydOnMgzzzwDmB17Bw8ezB133NFmx97HHnuM3/3ud6xatYoLLrig2bHGjr0LFizg17/+tftLRUdHq2OviJy5nPVmk9PX78CuD6CmrHvvHxQNw66A4VPM16DIjl9bWwlHNpoTEuZugbBEc7RX0iV9ajXythiGQWF5DUeOVRFg8yEq2E5EkK3dyf+OHKti3YFi1u4vYf2B4hYTGV4wdAB3Tx/F+YM7Vjvlchlk/Hs3z/83C4DvnZdAxg3nYvf1rMbN6TJ4Zd0hHl+1lxN1Tmy+Vu6aMoJbLxnaqQkN650u8h3VHDl2giPHq8g5VkXO8ROEBfqx6NqzPb7fqXhliPXs2bN57rnnmDhxIkuWLOGtt95iz549xMTEMGvWLBISEsjIyADM4dMLFy7kjTfeYPLkye77BAcHExwc7D7nkUceaTbEevv27RpiLSICZh+a/Znm8giuenDWNmx1Ld/X15jrSNWdaFim4UTD1vi+qvXPiBsLw6aYoSYxrfnsxCeHlkNrzZFWbY3Oih5jLv2QfAkkTQb/sO5/Hn2AYRjsLShn7b5i1h0oYe2+YvecOOmjY1gw7SxGxbb996iqtp5fvbmNj3YVAPDrqWdxxxXDuzRP0JFjVfzmva/57JsiwBzefttlw/C1Wql3uah3GjhdBvUuA6fL1fBqUFXr5OhxM7AcOV5FXml1q5MkJg4I4L93X9Hp8rXGK5PdLV261D3ZXWpqKk8//TRpaWkAXHbZZSQlJfHyyy8DkJSUxOHDh1vcY9GiRTzwwANA02R3f/rTnygtLeWiiy7ij3/8I2eddVaHyqMQIyLSQYZhhpKjX5rB6MB/zD45J7MFmyFk4DA4sqn10BI6CJIugsQJUHIQsj6Dgh3Nz7FYIf48815xY8372oLMJi33a6C5v4NLOvRVR0tP8PQn+3h78xFchtlSN2NsPP879SyGDGy+9laBo5qfvvIlO46WYfO18vj3U5iRmtAt5TAMg/e35bL4g53NZj72lM3HSkJEAIMiAhgUEUjigACSBgZx9bndOxJKyw6gECMi0iXl+eaw7wMNoaaqpOU5oYPMmYeTLjK38CEt+9RUlsChz8xAc3BN8zWp2mP1M5eEiE2BxInmljAeAsK79NV624GiCp786Bv+tcNc1sLXamHmhER+OWUEMaH+7Mp1cMsrm8grq2ZAkI0//Xgc45M6tlq6J0oqavjDJ9+wO68cX6sFXx8LPlYrvlYLPlaL+9XPx4rd10p8uBlYEgcEkhgRSHSIvVc6CCvEoBAjItJtXC7I/8qspSnLgUHj2w4t7SnLMQNN1mfmcgy1lSetRF5lNnGdcnFPC0SNagg1aebrwOH9okPy10fLeHzVXtY0NO34+1m5/rwE/rEtl8paJ0OjgnhpzoQWtTRnGoUYFGJERPqt+lozzNRWQmWR2XR1ZKO5Hc9qeX7AAIgaCSGx5oitxtfgmKaf7SF9JuhsOFjCY6v2svlw09pdk4YOZPmPxhEW2L+b0LqDQgwKMSIip6WKQjPM5DSEmqNbwFnT/nV+QeYcO4YLDCe4nE2vJ783XGbH46BICIw0X4MiISiq4eeB5nvfAPNz62uaOk+f/NrYsdrX3rAFNLz6g58/ho+dL49WsWJrIUOiw/nZpSOw+fmafYYsPuarteHVYm0YBt//Jq7rDIUYFGJERM4I9bVm5+Hjh81+PBX55mt5XsNrQfcPRfcGqy8MmmDO2Dzscog/H3y6eW7amnLY/QF89SbkboOE8821vEZcCZHDu/ezTkEhBoUYERFpUFtpBpoTpWC1moHA4mPWdFh9T6r18DGbnKrLoLLYbMqqKjFfv/1zfTX4NNSy+Nhaf7X6NdXW1Febr3UnTvq5Ydi74TT7HTXWEhmuplqhtlZAt4dC0sVmoBl6uTlqrDPNZS4nHFxtBpc9/2x7uP2AoQ2BZioMuahHa4UUYlCIERGR04BhmGGmNNsMGwc/NUd5VZc2Py90kLnyedRZDf2A4iA03uwPZGulo3DBTvjqr7D9bbP2qtGAYTD2B+ZEhUc2wr5VcHh98+H0foHmvD8jpprBJjyxW7+yQgwKMSIicppyOSFvmxlqDnwKRzaYfXDaYg+D0JM6PBd8Dfknzd8TEGGulj72B5AwrmWNTrUDstaYi5Pu+7h56LGFwD1Z3Tqnj0IMCjEiInKGqK2E7PVweJ05hN2Ra/YJcuSZo7xaY/WDkdMh5SazNqWjK6MbhhmA9n1kbiFxcOMr3fddUIgBFGJERESodjQEmtyGjs65EDgQRn8XArthQj2Xy+xn1I26+ve7m7s7i4iIiFf4h5pb1MieuX83B5ju0PdKJCIiItIBCjEiIiLSLynEiIiISL+kECMiIiL9kkKMiIiI9EsKMSIiItIvKcSIiIhIv6QQIyIiIv2SQoyIiIj0SwoxIiIi0i8pxIiIiEi/pBAjIiIi/ZJCjIiIiPRLp8Uq1oZhAOaS3iIiItI/NP7dbvw77qnTIsSUl5cDkJiY6OWSiIiIiKfKy8sJCwvz+DqL0dn404e4XC5yc3MJCQnBYrF0670dDgeJiYkcOXKE0NDQbr23tE3P3Tv03L1Dz9079Ny94+TnHhISQnl5OfHx8VitnvdwOS1qYqxWK4MGDerRzwgNDdU/ci/Qc/cOPXfv0HP3Dj1372h87p2pgWmkjr0iIiLSLynEiIiISL+kENMOu93OokWLsNvt3i7KGUXP3Tv03L1Dz9079Ny9ozuf+2nRsVdERETOPKqJERERkX5JIUZERET6JYUYERER6ZcUYkRERKRfUog5hWXLlpGUlIS/vz9paWls3LjR20U67Xz22Wdce+21xMfHY7FYeO+995odNwyDhQsXEhcXR0BAAOnp6ezbt887hT1NZGRkMGHCBEJCQoiOjua6665j7969zc6prq7mF7/4BQMHDiQ4OJgbbriBgoICL5X49PDss8+SkpLinuBr0qRJ/Pvf/3Yf1zPvHY888ggWi4Vf/epX7n169t3vgQcewGKxNNtGjRrlPt5dz1whpg0rVqxg/vz5LFq0iC1btjB27FimTZtGYWGht4t2WqmsrGTs2LEsW7as1eOPPfYYTz/9NMuXL2fDhg0EBQUxbdo0qqure7mkp481a9bwi1/8gi+++IKPP/6Yuro6rrzySiorK93n/O///i8ffPABb7/9NmvWrCE3N5fvfe97Xix1/zdo0CAeeeQRNm/ezJdffskVV1zBjBkz2LlzJ6Bn3hs2bdrEc889R0pKSrP9evY94+yzzyYvL8+9rV271n2s2565Ia2aOHGi8Ytf/ML9s9PpNOLj442MjAwvlur0Bhjvvvuu+2eXy2XExsYajz/+uHtfaWmpYbfbjb/+9a9eKOHpqbCw0ACMNWvWGIZhPmM/Pz/j7bffdp+ze/duAzDWr1/vrWKeliIiIow///nPeua9oLy83BgxYoTx8ccfG5deeqlx1113GYahf+89ZdGiRcbYsWNbPdadz1w1Ma2ora1l8+bNpKenu/dZrVbS09NZv369F0t2ZsnKyiI/P7/Z7yEsLIy0tDT9HrpRWVkZAAMGDABg8+bN1NXVNXvuo0aNYvDgwXru3cTpdPLmm29SWVnJpEmT9Mx7wS9+8QuuueaaZs8Y9O+9J+3bt4/4+HiGDh3KzTffTHZ2NtC9z/y0WACyuxUXF+N0OomJiWm2PyYmhj179nipVGee/Px8gFZ/D43HpGtcLhe/+tWvmDx5Mueccw5gPnebzUZ4eHizc/Xcu27Hjh1MmjSJ6upqgoODeffddxkzZgzbtm3TM+9Bb775Jlu2bGHTpk0tjunfe89IS0vj5ZdfZuTIkeTl5bF48WIuvvhivv7662595goxImewX/ziF3z99dfN2qql54wcOZJt27ZRVlbGO++8w+zZs1mzZo23i3VaO3LkCHfddRcff/wx/v7+3i7OGeOqq65yv09JSSEtLY0hQ4bw1ltvERAQ0G2fo+akVkRGRuLj49Oip3RBQQGxsbFeKtWZp/FZ6/fQM+644w7++c9/8umnnzJo0CD3/tjYWGprayktLW12vp5719lsNoYPH864cePIyMhg7NixPPXUU3rmPWjz5s0UFhZy/vnn4+vri6+vL2vWrOHpp5/G19eXmJgYPfteEB4ezllnncX+/fu79d+7QkwrbDYb48aNIzMz073P5XKRmZnJpEmTvFiyM0tycjKxsbHNfg8Oh4MNGzbo99AFhmFwxx138O677/Kf//yH5OTkZsfHjRuHn59fs+e+d+9esrOz9dy7mcvloqamRs+8B02ZMoUdO3awbds29zZ+/Hhuvvlm93s9+55XUVHBgQMHiIuL695/713ofHxae/PNNw273W68/PLLxq5du4xbb73VCA8PN/Lz871dtNNKeXm5sXXrVmPr1q0GYDz55JPG1q1bjcOHDxuGYRiPPPKIER4ebrz//vvG9u3bjRkzZhjJycnGiRMnvFzy/uu2224zwsLCjNWrVxt5eXnuraqqyn3Oz3/+c2Pw4MHGf/7zH+PLL780Jk2aZEyaNMmLpe7/7r33XmPNmjVGVlaWsX37duPee+81LBaL8dFHHxmGoWfem04enWQYevY94de//rWxevVqIysry/j888+N9PR0IzIy0igsLDQMo/ueuULMKTzzzDPG4MGDDZvNZkycONH44osvvF2k086nn35qAC222bNnG4ZhDrO+//77jZiYGMNutxtTpkwx9u7d691C93OtPW/AeOmll9znnDhxwrj99tuNiIgIIzAw0Lj++uuNvLw87xX6NPCTn/zEGDJkiGGz2YyoqChjypQp7gBjGHrmvenbIUbPvvvNnDnTiIuLM2w2m5GQkGDMnDnT2L9/v/t4dz1zi2EYRjfUFImIiIj0KvWJERERkX5JIUZERET6JYUYERER6ZcUYkRERKRfUogRERGRfkkhRkRERPolhRgRERHplxRiREREpF9SiBEREZF+SSFGRERE+iWFGBEREemXFGJERESkX/r/AZRRPiHe23dkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_s, X_test_s = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# define a neural network using the keras sequential api\n",
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape = (X_train_s.shape[1])),\n",
    "    tf.keras.layers.Dense(\n",
    "      20, activation = 'tanh', name = 'hidden_layer'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(10, activation = 'tanh', name = 'hidden_layer2'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "my_model.compile(loss = 'binary_crossentropy', optimizer = 'Adam')\n",
    "my_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 2)\n",
    "history = my_model.fit(X_train_s, y_train, epochs = 50, validation_data = (X_test_s, y_test), callbacks = [my_callback])\n",
    "\n",
    "# we can visualize the evaluation of the loss during training\n",
    "# plt.plot(history.history['loss'], label = 'training')\n",
    "# plt.plot(history.history['val_loss'], label = 'validation')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 0s 1ms/step\n",
      "95/95 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "y_train_pred, y_test_pred = (my_model.predict(X_train_s).flatten() > 0.5)*1, (my_model.predict(X_test_s).flatten() > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kears</td>\n",
       "      <td>0.936371</td>\n",
       "      <td>0.855509</td>\n",
       "      <td>0.72511</td>\n",
       "      <td>0.784931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  Accuracy  Precision   Recall        F1\n",
       "0  kears  0.936371   0.855509  0.72511  0.784931"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"kears\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9518    0.9790    0.9652      5953\n",
      "           1     0.8705    0.7401    0.8000      1135\n",
      "\n",
      "    accuracy                         0.9407      7088\n",
      "   macro avg     0.9111    0.8595    0.8826      7088\n",
      "weighted avg     0.9388    0.9407    0.9388      7088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
